{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee074573",
   "metadata": {},
   "source": [
    "# LLM Baseline Project\n",
    "#*# I guess I'm building my highlight reel. I guess it's a deep fake of my best work. Knowledge is power, so let's retain what I've got as an LLM.\n",
    "#!# take out used_tts from summary functions\n",
    "#!# tts needs to be its own function?\n",
    "#!# coefficients need to go on the other side of the summaries. params after that.\n",
    "#!# function names are too long.\n",
    "#!# check defaults because they need to be divine based on what I'm looking for.\n",
    "\n",
    "#### Other Changes\n",
    "* simupter should have a strategy='auto'. Then it can look for a 0.80 correlation or higher and build a linear model. Since I have stepwise built, it would be interesting to have that **build a stepwise lm, pass it through train-test split, and accept or fail to reject the missing value imputation strategy.** KNN imputer might also be a good idea if I can develop a little in terms of KNN optimization.\n",
    "* catcoder would be awesome if it also worked with interval data. I want to implement **interval end truncation** for small sample sizes. This can maybe be called **grouper**.\n",
    "* This **grouper** idea requires a quick analysis of the data. It needs to be able to identify interval, categorical, and binary data. Then, many of the functions are in place to prep things appropriately and develop optimal models. I wonder how an LLM of all of teaching materials would do. \n",
    "* regularization of linear models should be automatic. There should be an option to regularize. **Maybe the option should be called optimize**.\n",
    "* perhaps yj_transformer should be more selective.\n",
    "* I kind of want to build a faster hp tuning module for tree models. Still refining my idea as the value counts will take up the most time. I think it would be interesting to start with value counts per lean feature first (limited ranges, such as 0/1; 1,2,3,4,5; etc.). This can be done with len(pd.unique()) and running value counts on the results (ascending). It will probably look something like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8499d600",
   "metadata": {},
   "source": [
    "~~~\n",
    "# perhaps this model should be called hangman\n",
    "hangman = << all available splits where samples > param(min_samples_leaf | min_samples_split) >>\n",
    "\n",
    "#^# check development time of the above and run a middlish-out (start at percentile 0.01 and 0.99 and move out from there.)\n",
    "\n",
    "# ... this is going to be my llm project btw.\n",
    "# Control for the really large features so unique doesn't have to run?\n",
    "\n",
    "hp_tree['data_diversity'] = len(pd.unique( <<feature>> ))\n",
    "hp_tree['data_diversity'].sort_values(ascending=True)\n",
    "\n",
    "\n",
    "# Start at the top (smallest hp_tree['data_diversity']) and work your way down.\n",
    "If param(min_samples_leaf | min_samples_split) > samples at first divide ... cross off the hangman list.\n",
    "\n",
    "# learn from the above and make faster splits on the next fold.\n",
    "~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5152dfc8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>m_Lot_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Second_Flr_SF</th>\n",
       "      <th>log_Sale_Price</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Gr_Liv_Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot_Config</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31770</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1080</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>528.0</td>\n",
       "      <td>272</td>\n",
       "      <td>215000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.278398</td>\n",
       "      <td>10.366309</td>\n",
       "      <td>7.412764</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Corner</td>\n",
       "      <td>NAmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>882</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896</td>\n",
       "      <td>730.0</td>\n",
       "      <td>260</td>\n",
       "      <td>105000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.561725</td>\n",
       "      <td>9.360741</td>\n",
       "      <td>6.799056</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>NAmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14267</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>312.0</td>\n",
       "      <td>429</td>\n",
       "      <td>172000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.055256</td>\n",
       "      <td>9.565775</td>\n",
       "      <td>7.192934</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Corner</td>\n",
       "      <td>NAmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0</td>\n",
       "      <td>244000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.404928</td>\n",
       "      <td>9.320181</td>\n",
       "      <td>7.654917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Corner</td>\n",
       "      <td>NAmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>928</td>\n",
       "      <td>928.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1629</td>\n",
       "      <td>482.0</td>\n",
       "      <td>246</td>\n",
       "      <td>189900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.154258</td>\n",
       "      <td>9.534668</td>\n",
       "      <td>7.396335</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gilbert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id  Lot_Area  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Garage_Area  Porch_Area  Sale_Price  m_Lot_Area  m_Mas_Vnr_Area  m_Second_Flr_SF  log_Sale_Price  log_Lot_Area  log_Gr_Liv_Area Street Lot_Config Neighborhood\n",
       "0            1     31770         112.0           1080        1656.0            0.0         1656        528.0         272      215000           0               0                0       12.278398     10.366309         7.412764   Pave     Corner        NAmes\n",
       "1            2     11622           0.0            882         896.0            0.0          896        730.0         260      105000           0               0                0       11.561725      9.360741         6.799056   Pave     Inside        NAmes\n",
       "2            3     14267         108.0           1329        1329.0            0.0         1329        312.0         429      172000           0               0                0       12.055256      9.565775         7.192934   Pave     Corner        NAmes\n",
       "3            4     11160           0.0           2110        2110.0            0.0         2110        522.0           0      244000           0               1                0       12.404928      9.320181         7.654917   Pave     Corner        NAmes\n",
       "4            5     13830           0.0            928         928.0          701.0         1629        482.0         246      189900           0               0                0       12.154258      9.534668         7.396335   Pave     Inside      Gilbert"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd                   # data science essentials\n",
    "import matplotlib.pyplot as plt       # essential graphical output\n",
    "import seaborn as sns                 # enhanced graphical output\n",
    "import numpy as np                    # mathematical essentials\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "import warnings                       # warnings\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# suppressing warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "\n",
    "# specifying file path\n",
    "file = './datasets/ames_transformed.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "housing = pd.read_excel(io     = file,\n",
    "                        header = 0   )\n",
    "\n",
    "# importing interval and count data\n",
    "file = './datasets/ames_non_continuous.xlsx'\n",
    "\n",
    "housing_2 = pd.read_excel(io         = file,\n",
    "                          header     = 0,\n",
    "                          sheet_name = 'categorical_discrete')\n",
    "\n",
    "\n",
    "# documentation: help(pd.DataFrame.merge)\n",
    "\n",
    "# merging the two datasets\n",
    "housing = housing.merge(right = housing_2,\n",
    "                        on    = 'property_id',\n",
    "                        how   = 'left')\n",
    "\n",
    "\n",
    "# checking results\n",
    "housing.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bf29b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from baserush import preprocess\n",
    "from baserush import summary\n",
    "from baserush import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0fe0d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function simputer in module baserush.preprocess:\n",
      "\n",
      "simputer(df: 'ArrayLike', include: 'Optional[Sequence[str]]' = None, strategy: 'str' = 'mean', fill_value: 'Optional[Any]' = None, add_indicator: 'bool' = False, return_imputer: 'bool' = False) -> 'Union[pd.DataFrame, Tuple[pd.DataFrame, SimpleImputer]]'\n",
      "    Imputes missing values on numeric columns (default: mean). Strategies\n",
      "    include: 'mean'|'median'|'most_frequent'|'constant'.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    df             | DataFrame | data to be imputed            | No default.\n",
      "    include        | list-like | features to impute            | Default = None\n",
      "    strategy       | str       | imputation strategy to apply  | Default = \"mean\"\n",
      "    fill_value     | numeric   | fill for strategy='constant'  | Default = None\n",
      "    flag_feature   | bool      | binary flag identifying an    | Default = False\n",
      "                   |           | originally missing value      |\n",
      "    return_imputer | bool      | returns fitted imputer object | Default = False\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    DataFrame (and optionally fitted imputer object)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(preprocess.simputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1121cc2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# simputer\n",
    "housing2 = preprocess.simputer(df         = housing,\n",
    "                               strategy   = 'mean',\n",
    "                               fill_value = -1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36ef40b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function catcoder in module baserush.preprocess:\n",
      "\n",
      "catcoder(data: 'ArrayLike', min_samples: 'int' = 100, drop_most: 'bool' = False) -> 'pd.DataFrame'\n",
      "    Encodes categorical features for use in machine learning models.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    data          | DF|Series | feature(s) to be categorically encoded  | No default.\n",
      "    min_samples   | numeric   | minimum samples required for each new   | Default = 100\n",
      "                              | categorical feature.                    |\n",
      "    drop_most     | bool      | drops most frequent categorical feature | Default = False\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    A DataFrame containing categorically-encoded features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(preprocess.catcoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04f5e19",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>m_Lot_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Second_Flr_SF</th>\n",
       "      <th>log_Sale_Price</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Gr_Liv_Area</th>\n",
       "      <th>Lot_Config_Corner</th>\n",
       "      <th>Lot_Config_CulDSac</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31770</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1080</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>528.0</td>\n",
       "      <td>272</td>\n",
       "      <td>215000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.278398</td>\n",
       "      <td>10.366309</td>\n",
       "      <td>7.412764</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>882</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896</td>\n",
       "      <td>730.0</td>\n",
       "      <td>260</td>\n",
       "      <td>105000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.561725</td>\n",
       "      <td>9.360741</td>\n",
       "      <td>6.799056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14267</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>312.0</td>\n",
       "      <td>429</td>\n",
       "      <td>172000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.055256</td>\n",
       "      <td>9.565775</td>\n",
       "      <td>7.192934</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0</td>\n",
       "      <td>244000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.404928</td>\n",
       "      <td>9.320181</td>\n",
       "      <td>7.654917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>928</td>\n",
       "      <td>928.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1629</td>\n",
       "      <td>482.0</td>\n",
       "      <td>246</td>\n",
       "      <td>189900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.154258</td>\n",
       "      <td>9.534668</td>\n",
       "      <td>7.396335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id  Lot_Area  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Garage_Area  Porch_Area  Sale_Price  m_Lot_Area  m_Mas_Vnr_Area  m_Second_Flr_SF  log_Sale_Price  log_Lot_Area  log_Gr_Liv_Area  Lot_Config_Corner  Lot_Config_CulDSac  Neighborhood_BrkSide  Neighborhood_CollgCr  Neighborhood_Crawfor  Neighborhood_Edwards  Neighborhood_Gilbert  Neighborhood_Mitchel  Neighborhood_NAmes  Neighborhood_NWAmes  Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst\n",
       "0            1     31770         112.0           1080        1656.0            0.0         1656        528.0         272      215000           0               0                0       12.278398     10.366309         7.412764                  1                   0                     0                     0                     0                     0                     0                     0                   1                    0                     0                     0                    0                     0                     0\n",
       "1            2     11622           0.0            882         896.0            0.0          896        730.0         260      105000           0               0                0       11.561725      9.360741         6.799056                  0                   0                     0                     0                     0                     0                     0                     0                   1                    0                     0                     0                    0                     0                     0\n",
       "2            3     14267         108.0           1329        1329.0            0.0         1329        312.0         429      172000           0               0                0       12.055256      9.565775         7.192934                  1                   0                     0                     0                     0                     0                     0                     0                   1                    0                     0                     0                    0                     0                     0\n",
       "3            4     11160           0.0           2110        2110.0            0.0         2110        522.0           0      244000           0               1                0       12.404928      9.320181         7.654917                  1                   0                     0                     0                     0                     0                     0                     0                   1                    0                     0                     0                    0                     0                     0\n",
       "4            5     13830           0.0            928         928.0          701.0         1629        482.0         246      189900           0               0                0       12.154258      9.534668         7.396335                  0                   0                     0                     0                     0                     0                     1                     0                   0                    0                     0                     0                    0                     0                     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catcoder\n",
    "cat_data = preprocess.catcoder(data        = housing2[ ['Lot_Config', 'Street', 'Neighborhood'] ],\n",
    "                               min_samples = 100,\n",
    "                               drop_most   = True)\n",
    "\n",
    "housing3 = pd.concat(objs = [housing2, cat_data], axis = 1)\n",
    "housing3.drop(labels = ['Street', 'Lot_Config', 'Neighborhood'],\n",
    "              axis = 1,\n",
    "              inplace = True)\n",
    "\n",
    "\n",
    "print(housing3.shape)\n",
    "housing3.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08868290",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function simple_scaler in module baserush.preprocess:\n",
      "\n",
      "simple_scaler(df: 'ArrayLike', include: 'Optional[Sequence[str]]' = None, with_mean: 'bool' = True, with_std: 'bool' = True, copy: 'bool' = True, return_scaler: 'bool' = False) -> 'Union[pd.DataFrame, Tuple[pd.DataFrame, StandardScaler]]'\n",
      "    Standardizes a dataset (μ = 0, σ² = 1).\n",
      "    Requires sklearn.preprocessing.StandardScaler()\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    df            | DataFrame  | data to be used for scaling  | No default.\n",
      "    include       | list-like  | features to scale            | Default = None\n",
      "    with_mean     | bool       | scale w/ feature means       | Default = True\n",
      "    with_std      | bool       | scale w/ standard deviations | Default = True\n",
      "    copy          | bool       | features to scale            | Default = True\n",
      "    return_scaler | bool       | returns fitted scaler object | Default = False\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    DataFrame (and optionally fitted scaler object)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(preprocess.simple_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c23853",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>m_Lot_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Second_Flr_SF</th>\n",
       "      <th>log_Sale_Price</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Gr_Liv_Area</th>\n",
       "      <th>Lot_Config_Corner</th>\n",
       "      <th>Lot_Config_CulDSac</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731460</td>\n",
       "      <td>2.751017</td>\n",
       "      <td>0.068434</td>\n",
       "      <td>0.065196</td>\n",
       "      <td>1.272762</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>0.309393</td>\n",
       "      <td>0.257767</td>\n",
       "      <td>0.557600</td>\n",
       "      <td>0.428229</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.631690</td>\n",
       "      <td>2.511909</td>\n",
       "      <td>0.468303</td>\n",
       "      <td>2.175742</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.730277</td>\n",
       "      <td>0.190709</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>-0.383893</td>\n",
       "      <td>-0.672156</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>-1.194072</td>\n",
       "      <td>1.196882</td>\n",
       "      <td>0.482510</td>\n",
       "      <td>-0.948957</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>-1.126954</td>\n",
       "      <td>0.531879</td>\n",
       "      <td>-1.422519</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.729095</td>\n",
       "      <td>0.526823</td>\n",
       "      <td>0.045796</td>\n",
       "      <td>0.629959</td>\n",
       "      <td>0.435935</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>-0.337493</td>\n",
       "      <td>-0.746435</td>\n",
       "      <td>1.540035</td>\n",
       "      <td>-0.110125</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.084121</td>\n",
       "      <td>0.935603</td>\n",
       "      <td>-0.208988</td>\n",
       "      <td>2.175742</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.727913</td>\n",
       "      <td>0.132001</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>2.401365</td>\n",
       "      <td>2.434594</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>1.207515</td>\n",
       "      <td>0.229873</td>\n",
       "      <td>-1.144451</td>\n",
       "      <td>0.791305</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>5.785377</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.942181</td>\n",
       "      <td>0.452013</td>\n",
       "      <td>1.214372</td>\n",
       "      <td>2.175742</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.726731</td>\n",
       "      <td>0.471291</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>-0.279559</td>\n",
       "      <td>-0.590265</td>\n",
       "      <td>0.860032</td>\n",
       "      <td>0.255980</td>\n",
       "      <td>0.043909</td>\n",
       "      <td>0.394904</td>\n",
       "      <td>0.113980</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.327063</td>\n",
       "      <td>0.874352</td>\n",
       "      <td>0.417687</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>4.093602</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>1.726731</td>\n",
       "      <td>-0.277562</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>-0.109450</td>\n",
       "      <td>-0.398332</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>-0.982400</td>\n",
       "      <td>0.536712</td>\n",
       "      <td>-0.393546</td>\n",
       "      <td>-0.479462</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>-0.377584</td>\n",
       "      <td>-0.218974</td>\n",
       "      <td>-1.075319</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>3.908680</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>4.970086</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>1.727913</td>\n",
       "      <td>-0.157095</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>-0.424719</td>\n",
       "      <td>-0.656801</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>-1.182203</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>-0.118214</td>\n",
       "      <td>-0.623440</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>-0.584065</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>-1.401979</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>4.970086</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>1.729095</td>\n",
       "      <td>0.040634</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>-0.315849</td>\n",
       "      <td>-0.482783</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>-1.047682</td>\n",
       "      <td>-2.196949</td>\n",
       "      <td>-0.443606</td>\n",
       "      <td>-0.610920</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>-0.565404</td>\n",
       "      <td>0.320894</td>\n",
       "      <td>-1.178288</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>4.970086</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>1.730277</td>\n",
       "      <td>-0.014136</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>0.766047</td>\n",
       "      <td>0.589481</td>\n",
       "      <td>-0.785877</td>\n",
       "      <td>-0.218798</td>\n",
       "      <td>-0.253632</td>\n",
       "      <td>0.595146</td>\n",
       "      <td>-0.135165</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.237895</td>\n",
       "      <td>-0.073040</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>4.970086</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>1.731460</td>\n",
       "      <td>-0.062805</td>\n",
       "      <td>-0.033438</td>\n",
       "      <td>-0.125327</td>\n",
       "      <td>-0.416246</td>\n",
       "      <td>1.571460</td>\n",
       "      <td>0.989908</td>\n",
       "      <td>0.824955</td>\n",
       "      <td>0.344844</td>\n",
       "      <td>0.090192</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.302388</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>1.049494</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>4.970086</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      property_id  Lot_Area  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Garage_Area  Porch_Area  Sale_Price  m_Lot_Area  m_Mas_Vnr_Area  m_Second_Flr_SF  log_Sale_Price  log_Lot_Area  log_Gr_Liv_Area  Lot_Config_Corner  Lot_Config_CulDSac  Neighborhood_BrkSide  Neighborhood_CollgCr  Neighborhood_Crawfor  Neighborhood_Edwards  Neighborhood_Gilbert  Neighborhood_Mitchel  Neighborhood_NAmes  Neighborhood_NWAmes  Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst\n",
       "0       -1.731460  2.751017      0.068434       0.065196      1.272762      -0.785877     0.309393     0.257767    0.557600    0.428229   -0.178017       -0.172850        -0.282112        0.631690      2.511909         0.468303           2.175742           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "1       -1.730277  0.190709     -0.565435      -0.383893     -0.672156      -0.785877    -1.194072     1.196882    0.482510   -0.948957   -0.178017       -0.172850        -0.282112       -1.126954      0.531879        -1.422519          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "2       -1.729095  0.526823      0.045796       0.629959      0.435935      -0.785877    -0.337493    -0.746435    1.540035   -0.110125   -0.178017       -0.172850        -0.282112        0.084121      0.935603        -0.208988           2.175742           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "3       -1.727913  0.132001     -0.565435       2.401365      2.434594      -0.785877     1.207515     0.229873   -1.144451    0.791305   -0.178017        5.785377        -0.282112        0.942181      0.452013         1.214372           2.175742           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "4       -1.726731  0.471291     -0.565435      -0.279559     -0.590265       0.860032     0.255980     0.043909    0.394904    0.113980   -0.178017       -0.172850        -0.282112        0.327063      0.874352         0.417687          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283              4.093602             -0.201204           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "...           ...       ...           ...            ...           ...            ...          ...          ...         ...         ...         ...             ...              ...             ...           ...              ...                ...                 ...                   ...                   ...                   ...                   ...                   ...                   ...                 ...                  ...                   ...                   ...                  ...                   ...                   ...\n",
       "2925     1.726731 -0.277562     -0.565435      -0.109450     -0.398332      -0.785877    -0.982400     0.536712   -0.393546   -0.479462   -0.178017       -0.172850        -0.282112       -0.377584     -0.218974        -1.075319          -0.459613            3.908680             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284              4.970086           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "2926     1.727913 -0.157095     -0.565435      -0.424719     -0.656801      -0.785877    -1.182203     0.053208   -0.118214   -0.623440   -0.178017       -0.172850        -0.282112       -0.584065      0.003167        -1.401979          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284              4.970086           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "2927     1.729095  0.040634     -0.565435      -0.315849     -0.482783      -0.785877    -1.047682    -2.196949   -0.443606   -0.610920   -0.178017       -0.172850        -0.282112       -0.565404      0.320894        -1.178288          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284              4.970086           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "2928     1.730277 -0.014136     -0.565435       0.766047      0.589481      -0.785877    -0.218798    -0.253632    0.595146   -0.135165   -0.178017       -0.172850        -0.282112        0.055420      0.237895        -0.073040          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284              4.970086           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "2929     1.731460 -0.062805     -0.033438      -0.125327     -0.416246       1.571460     0.989908     0.824955    0.344844    0.090192   -0.178017       -0.172850        -0.282112        0.302388      0.161083         1.049494          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284              4.970086           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "\n",
       "[2930 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard_scaler\n",
    "housing4 = preprocess.simple_scaler(df            = housing3,\n",
    "                                    #include       = ['Sale_Price', 'Mas_Vnr_Area'],\n",
    "                                    with_mean     = True,\n",
    "                                    with_std      = True,\n",
    "                                    return_scaler = False)\n",
    "\n",
    "housing4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1685ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function transtorm in module baserush.preprocess:\n",
      "\n",
      "transtorm(df: 'ArrayLike', include: 'Optional[Sequence[str]]' = None, verbose: 'bool' = True, standardize: 'bool' = True, return_transformer: 'bool' = False) -> 'Union[pd.DataFrame, Tuple[pd.DataFrame, PowerTransformer]]'\n",
      "    Performs a Yeo-Johnson transformation on numeric features to reduce\n",
      "    skewness.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    df            | DataFrame | data to be transformed       | No default.\n",
      "    include       | list-like | features to transform        | Default = None\n",
      "    verbose       | bool      | print a summary of results   | Default = False\n",
      "    standardize   | bool      | standardizes each feature    | Default = True\n",
      "    return_transformer | bool | returns fitted scaler object | Default = False\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    DataFrame (and optionally fitted transformer object)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(preprocess.transtorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ee9e06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>m_Lot_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Second_Flr_SF</th>\n",
       "      <th>log_Sale_Price</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Gr_Liv_Area</th>\n",
       "      <th>Lot_Config_Corner</th>\n",
       "      <th>Lot_Config_CulDSac</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731460</td>\n",
       "      <td>2.546762</td>\n",
       "      <td>0.842800</td>\n",
       "      <td>0.157079</td>\n",
       "      <td>1.262342</td>\n",
       "      <td>-0.847883</td>\n",
       "      <td>0.493342</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.753187</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.637675</td>\n",
       "      <td>2.840194</td>\n",
       "      <td>0.468202</td>\n",
       "      <td>2.175742</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.730277</td>\n",
       "      <td>0.585772</td>\n",
       "      <td>-0.759253</td>\n",
       "      <td>-0.322217</td>\n",
       "      <td>-0.657225</td>\n",
       "      <td>-0.847883</td>\n",
       "      <td>-1.450145</td>\n",
       "      <td>1.183752</td>\n",
       "      <td>0.690537</td>\n",
       "      <td>-1.219897</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>-1.131720</td>\n",
       "      <td>0.503759</td>\n",
       "      <td>-1.422372</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.729095</td>\n",
       "      <td>1.021194</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.693379</td>\n",
       "      <td>0.620725</td>\n",
       "      <td>-0.847883</td>\n",
       "      <td>-0.207762</td>\n",
       "      <td>-0.738255</td>\n",
       "      <td>1.434914</td>\n",
       "      <td>0.141806</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.095497</td>\n",
       "      <td>0.952087</td>\n",
       "      <td>-0.209118</td>\n",
       "      <td>2.175742</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.727913</td>\n",
       "      <td>0.496499</td>\n",
       "      <td>-0.759253</td>\n",
       "      <td>2.121355</td>\n",
       "      <td>1.958392</td>\n",
       "      <td>-0.847883</td>\n",
       "      <td>1.211949</td>\n",
       "      <td>0.259310</td>\n",
       "      <td>-1.448939</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>5.785377</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.942240</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>1.214448</td>\n",
       "      <td>2.175742</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>-0.244284</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>2.369387</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.726731</td>\n",
       "      <td>0.956688</td>\n",
       "      <td>-0.759253</td>\n",
       "      <td>-0.206483</td>\n",
       "      <td>-0.540278</td>\n",
       "      <td>1.084748</td>\n",
       "      <td>0.443202</td>\n",
       "      <td>0.075020</td>\n",
       "      <td>0.614770</td>\n",
       "      <td>0.400909</td>\n",
       "      <td>-0.178017</td>\n",
       "      <td>-0.172850</td>\n",
       "      <td>-0.282112</td>\n",
       "      <td>0.336964</td>\n",
       "      <td>0.882940</td>\n",
       "      <td>0.417578</td>\n",
       "      <td>-0.459613</td>\n",
       "      <td>-0.255841</td>\n",
       "      <td>-0.195629</td>\n",
       "      <td>-0.316643</td>\n",
       "      <td>-0.190878</td>\n",
       "      <td>-0.266283</td>\n",
       "      <td>4.093602</td>\n",
       "      <td>-0.201204</td>\n",
       "      <td>-0.422050</td>\n",
       "      <td>-0.216339</td>\n",
       "      <td>-0.245067</td>\n",
       "      <td>-0.298018</td>\n",
       "      <td>-0.233101</td>\n",
       "      <td>-0.2111</td>\n",
       "      <td>-0.257352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id  Lot_Area  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Garage_Area  Porch_Area  Sale_Price  m_Lot_Area  m_Mas_Vnr_Area  m_Second_Flr_SF  log_Sale_Price  log_Lot_Area  log_Gr_Liv_Area  Lot_Config_Corner  Lot_Config_CulDSac  Neighborhood_BrkSide  Neighborhood_CollgCr  Neighborhood_Crawfor  Neighborhood_Edwards  Neighborhood_Gilbert  Neighborhood_Mitchel  Neighborhood_NAmes  Neighborhood_NWAmes  Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst\n",
       "0    -1.731460  2.546762      0.842800       0.157079      1.262342      -0.847883     0.493342     0.286726    0.753187    0.701772   -0.178017       -0.172850        -0.282112        0.637675      2.840194         0.468202           2.175742           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "1    -1.730277  0.585772     -0.759253      -0.322217     -0.657225      -0.847883    -1.450145     1.183752    0.690537   -1.219897   -0.178017       -0.172850        -0.282112       -1.131720      0.503759        -1.422372          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "2    -1.729095  1.021194      0.811966       0.693379      0.620725      -0.847883    -0.207762    -0.738255    1.434914    0.141806   -0.178017       -0.172850        -0.282112        0.095497      0.952087        -0.209118           2.175742           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "3    -1.727913  0.496499     -0.759253       2.121355      1.958392      -0.847883     1.211949     0.259310   -1.448939    0.989161   -0.178017        5.785377        -0.282112        0.942240      0.417296         1.214448           2.175742           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283             -0.244284             -0.201204            2.369387            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352\n",
       "4    -1.726731  0.956688     -0.759253      -0.206483     -0.540278       1.084748     0.443202     0.075020    0.614770    0.400909   -0.178017       -0.172850        -0.282112        0.336964      0.882940         0.417578          -0.459613           -0.255841             -0.195629             -0.316643             -0.190878             -0.266283              4.093602             -0.201204           -0.422050            -0.216339             -0.245067             -0.298018            -0.233101               -0.2111             -0.257352"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yj_transformer\n",
    "housing5 = preprocess.transtorm(df      = housing4,\n",
    "                                #include = ['Lot_Area', 'Total_Bsmt_SF'],\n",
    "                                verbose = False,\n",
    "                                return_transformer = False)\n",
    "\n",
    "housing5.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbca1814",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "## summary ##\n",
    "#!# both summaries are broken... but I might have just fixed them.\n",
    "#!# coefficients need to go on the other side. params after that.\n",
    "#!# function names are too long. \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree         import DecisionTreeRegressor\n",
    "from sklearn.neighbors    import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b673af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tree_summary in module baserush.summary:\n",
      "\n",
      "tree_summary(x: 'ArrayLike', y: 'ArrayLike', model: 'BaseEstimator', model_name: 'str' = '', results_df: 'Optional[pd.DataFrame]' = None, f_names: 'Optional[Sequence[str]]' = None, tree_params: 'bool' = True, tts: 'bool' = True, test_size: 'float' = 0.25, random_state: 'int' = 702) -> 'pd.DataFrame'\n",
      "    This function is designed validate and summarize the following tree-based\n",
      "    models from scikit-learn:\n",
      "\n",
      "    sklearn.tree\n",
      "        * DecisionTreeRegressor - A decision tree regressor.\n",
      "        * ExtraTreeRegressor    - An extremely randomized tree regressor.\n",
      "\n",
      "    sklearn.ensemble\n",
      "        * RandomForestRegressor     - A random forest regressor.\n",
      "        * GradientBoostingRegressor - Gradient Boosting for regression.\n",
      "        * ExtraTreesRegressor       - An extra-trees regressor.\n",
      "        * RandomTreesEmbedding      - An ensemble of totally random trees.\n",
      "\n",
      "    This function will:\n",
      "    1) Split the data into training and validation sets (optional).\n",
      "    2) Fit a model type to the training data.\n",
      "    3) Calculate R-Square for the training and validation sets, as well as\n",
      "       the train-test gap and feature importances.\n",
      "    4) Provide hyperparameter values (optional)\n",
      "    5) Retrun the results as a DataFrame.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    x            | array     | X-data before train-test split     | No default.\n",
      "    y            | array     | y-data before train-test split     | No default.\n",
      "    model        | model     | model object to instantiate        | No default.\n",
      "    model_name   | str       | model name (recommended)           | Default = \"\"\n",
      "    results_df   | DataFrame | optional results df                | Default = None\n",
      "    f_names      | list      | full feature names for all x-sets  | Default = None\n",
      "    tree_params  | bool      | include hyperparameters in results | Default = True\n",
      "    tts          | bool      | perform train_test_split           | Default = True\n",
      "    test_size    | float     | test proportion (tts)              | Default = 0.25\n",
      "    random_state | int       | seed (tts)                         | Default = 702\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    A DataFrame with one row per call; will concatenate over multiple calls.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(summary.tree_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d855526b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "x_data = housing4.drop(['property_id', 'Sale_Price', 'log_Sale_Price'], axis = 1)\n",
    "y_data = housing4['Sale_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50fcceff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model_Class</th>\n",
       "      <th>Model_Type</th>\n",
       "      <th>train_RSQ</th>\n",
       "      <th>test_RSQ</th>\n",
       "      <th>tt_gap</th>\n",
       "      <th>used_tts</th>\n",
       "      <th>hp_ccp_alpha</th>\n",
       "      <th>hp_criterion</th>\n",
       "      <th>hp_max_depth</th>\n",
       "      <th>hp_max_features</th>\n",
       "      <th>hp_max_leaf_nodes</th>\n",
       "      <th>hp_min_impurity_decrease</th>\n",
       "      <th>hp_min_samples_leaf</th>\n",
       "      <th>hp_min_samples_split</th>\n",
       "      <th>hp_min_weight_fraction_leaf</th>\n",
       "      <th>hp_monotonic_cst</th>\n",
       "      <th>hp_random_state</th>\n",
       "      <th>hp_splitter</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>m_Lot_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Second_Flr_SF</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Gr_Liv_Area</th>\n",
       "      <th>Lot_Config_Corner</th>\n",
       "      <th>Lot_Config_CulDSac</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>sklearn.tree._classes</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>best</td>\n",
       "      <td>0.013609</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.182411</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.376647</td>\n",
       "      <td>0.227845</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.00327</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.002542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model_Name            Model_Class             Model_Type  train_RSQ  test_RSQ  tt_gap  used_tts  hp_ccp_alpha   hp_criterion hp_max_depth hp_max_features hp_max_leaf_nodes  hp_min_impurity_decrease  hp_min_samples_leaf  hp_min_samples_split  hp_min_weight_fraction_leaf hp_monotonic_cst hp_random_state hp_splitter  Lot_Area  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Garage_Area  Porch_Area  m_Lot_Area  m_Mas_Vnr_Area  m_Second_Flr_SF  log_Lot_Area  log_Gr_Liv_Area  Lot_Config_Corner  Lot_Config_CulDSac  Neighborhood_BrkSide  Neighborhood_CollgCr  Neighborhood_Crawfor  Neighborhood_Edwards  Neighborhood_Gilbert  Neighborhood_Mitchel  Neighborhood_NAmes  Neighborhood_NWAmes  Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst\n",
       "0       test  sklearn.tree._classes  DecisionTreeRegressor        1.0    0.6323  0.3677      True           0.0  squared_error         None            None              None                       0.0                    1                     2                          0.0             None            None        best  0.013609        0.0185       0.182411      0.015999       0.014115     0.376647     0.227845    0.034951    0.000752        0.001435         0.000367      0.017258         0.043774           0.002195            0.002154              0.000092              0.001527              0.002724              0.003685              0.001114              0.002411            0.009871              0.00327              0.005481              0.012193             0.002655              0.000422              0.002542"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree_summary (importances, key stuff, params)...(key stuff, params, importances)\n",
    "model_type = DecisionTreeRegressor()\n",
    "\n",
    "summary.tree_summary(x     = x_data,\n",
    "                     y     = y_data,\n",
    "                     model = model_type,\n",
    "                     model_name = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "957b9fd3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function lr_summary in module baserush.summary:\n",
      "\n",
      "lr_summary(x: 'ArrayLike', y: 'ArrayLike', model: 'BaseEstimator', model_name: 'str' = '', results_df: 'Optional[pd.DataFrame]' = None, starter: 'Optional[Dict[str, Any]]' = None, f_names: 'Optional[Sequence[str]]' = None, tts: 'bool' = True, test_size: 'float' = 0.25, random_state: 'int' = 702) -> 'pd.DataFrame'\n",
      "    This function is designed validate and summarize the following linear\n",
      "    models from scikit-learn:\n",
      "        * LinearRegression - OLS regression\n",
      "        * Lasso            - Lasso regression\n",
      "        * Ridge            - Ridge regression\n",
      "        * SGDRegressor     - Stochastic Gradient Descent\n",
      "\n",
      "    This function will:\n",
      "    1) Split the data into training and validation sets (optional).\n",
      "    2) Fit a model type to the training data.\n",
      "    3) Calculate R-Square for the training and validation sets, as well as\n",
      "       the train-test gap and model coefficients.\n",
      "    4) Retrun the results as a DataFrame.\n",
      "\n",
      "    Note: For models with multiple target features, only the first target's\n",
      "    coefficients will be stored.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    x            | array     | X-data before train-test split    | No default.\n",
      "    y            | array     | y-data before train-test split    | No default.\n",
      "    model        | model     | model object to instantiate       | No default.\n",
      "    model_name   | str       | model name (recommended)          | Default = \"\"\n",
      "    results_df   | DataFrame | optional results df               | Default = None\n",
      "    starter      | dict      | columns to include/override       | Default = None\n",
      "    f_names      | list      | full feature names for all x-sets | Default = None\n",
      "    tts          | bool      | perform train_test_split          | Default = True\n",
      "    test_size    | float     | test proportion (tts)             | Default = 0.25\n",
      "    random_state | int       | seed (tts)                        | Default = 702\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    A DataFrame with one row per call; will concatenate over multiple calls.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(summary.lr_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8658e5c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model_Class</th>\n",
       "      <th>Model_Type</th>\n",
       "      <th>train_RSQ</th>\n",
       "      <th>test_RSQ</th>\n",
       "      <th>tt_gap</th>\n",
       "      <th>used_tts</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>Second_Flr_SF</th>\n",
       "      <th>Gr_Liv_Area</th>\n",
       "      <th>Garage_Area</th>\n",
       "      <th>Porch_Area</th>\n",
       "      <th>m_Lot_Area</th>\n",
       "      <th>m_Mas_Vnr_Area</th>\n",
       "      <th>m_Second_Flr_SF</th>\n",
       "      <th>log_Lot_Area</th>\n",
       "      <th>log_Gr_Liv_Area</th>\n",
       "      <th>Lot_Config_Corner</th>\n",
       "      <th>Lot_Config_CulDSac</th>\n",
       "      <th>Neighborhood_BrkSide</th>\n",
       "      <th>Neighborhood_CollgCr</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_Edwards</th>\n",
       "      <th>Neighborhood_Gilbert</th>\n",
       "      <th>Neighborhood_Mitchel</th>\n",
       "      <th>Neighborhood_NAmes</th>\n",
       "      <th>Neighborhood_NWAmes</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>sklearn.linear_model._base</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>0.043</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>-0.0486</td>\n",
       "      <td>0.081468</td>\n",
       "      <td>0.190861</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.116477</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.163396</td>\n",
       "      <td>0.076933</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.119949</td>\n",
       "      <td>0.075422</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>0.053054</td>\n",
       "      <td>-0.053606</td>\n",
       "      <td>-0.010121</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>-0.1185</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.068753</td>\n",
       "      <td>-0.148665</td>\n",
       "      <td>-0.085236</td>\n",
       "      <td>0.160521</td>\n",
       "      <td>-0.141162</td>\n",
       "      <td>-0.092219</td>\n",
       "      <td>-0.045182</td>\n",
       "      <td>0.052647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model_Name                 Model_Class        Model_Type  train_RSQ  test_RSQ  tt_gap  used_tts  Intercept  Lot_Area  Mas_Vnr_Area  Total_Bsmt_SF  First_Flr_SF  Second_Flr_SF  Gr_Liv_Area  Garage_Area  Porch_Area  m_Lot_Area  m_Mas_Vnr_Area  m_Second_Flr_SF  log_Lot_Area  log_Gr_Liv_Area  Lot_Config_Corner  Lot_Config_CulDSac  Neighborhood_BrkSide  Neighborhood_CollgCr  Neighborhood_Crawfor  Neighborhood_Edwards  Neighborhood_Gilbert  Neighborhood_Mitchel  Neighborhood_NAmes  Neighborhood_NWAmes  Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst\n",
       "0             sklearn.linear_model._base  LinearRegression     0.7541    0.7971   0.043      True  -0.001952   -0.0486      0.081468       0.190861      0.127778       0.116477     0.116534     0.163396    0.076933    0.008947       -0.004801          0.00537      0.119949         0.075422          -0.020707            0.053054             -0.053606             -0.010121              0.012393               -0.1185             -0.004829             -0.068753           -0.148665            -0.085236              0.160521             -0.141162            -0.092219             -0.045182              0.052647"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_summary\n",
    "model_type = LinearRegression()\n",
    "\n",
    "summary.lr_summary(x = x_data,\n",
    "                   y = y_data,\n",
    "                   model = model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7ad361f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function knn_summary in module baserush.summary:\n",
      "\n",
      "knn_summary(x: 'ArrayLike', y: 'ArrayLike', model: 'BaseEstimator', model_name: 'str' = '', results_df: 'Optional[pd.DataFrame]' = None, f_names: 'Optional[Sequence[str]]' = None, tts: 'bool' = True, test_size: 'float' = 0.25, random_state: 'int' = 702, include_params: 'bool' = True) -> 'pd.DataFrame'\n",
      "    This function is designed to validate and summarize the following KNN-based\n",
      "    models from scikit-learn:\n",
      "\n",
      "    sklearn.neighbors\n",
      "        * KNeighborsRegressor - K-Nearest Neighbors regressor.\n",
      "        * RadiusNeighborsRegressor - Regression based on neighbors within a fixed radius.\n",
      "\n",
      "    This function will:\n",
      "    1) Split the data into training and validation sets (optional).\n",
      "    2) Fit a KNN model to the training data.\n",
      "    3) Calculate R-Square for the training and validation sets, as well as\n",
      "       the train-test gap.\n",
      "    4) Provide hyperparameter values (optional).\n",
      "    5) Return the results as a DataFrame.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    x             | array     | X-data before train-test split     | No default.\n",
      "    y             | array     | y-data before train-test split     | No default.\n",
      "    model         | model     | model object to instantiate        | No default.\n",
      "    model_name    | str       | model name (recommended)           | Default = \"\"\n",
      "    results_df    | DataFrame | optional results df                | Default = None\n",
      "    f_names       | list      | full feature names for all x-sets  | Default = None\n",
      "    tts           | bool      | perform train_test_split           | Default = True\n",
      "    test_size     | float     | test proportion (tts)              | Default = 0.25\n",
      "    random_state  | int       | seed (tts)                         | Default = 702\n",
      "    include_params| bool      | include hyperparameters in results | Default = True\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    A DataFrame with one row per call; will concatenate over multiple calls.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(summary.knn_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ccc8da1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model_Class</th>\n",
       "      <th>Model_Type</th>\n",
       "      <th>train_RSQ</th>\n",
       "      <th>test_RSQ</th>\n",
       "      <th>tt_gap</th>\n",
       "      <th>used_tts</th>\n",
       "      <th>hp_algorithm</th>\n",
       "      <th>hp_leaf_size</th>\n",
       "      <th>hp_metric</th>\n",
       "      <th>hp_metric_params</th>\n",
       "      <th>hp_n_jobs</th>\n",
       "      <th>hp_n_neighbors</th>\n",
       "      <th>hp_p</th>\n",
       "      <th>hp_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>sklearn.neighbors._regression</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.8411</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>True</td>\n",
       "      <td>auto</td>\n",
       "      <td>30</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model_Name                    Model_Class           Model_Type  train_RSQ  test_RSQ  tt_gap  used_tts hp_algorithm  hp_leaf_size  hp_metric hp_metric_params hp_n_jobs  hp_n_neighbors  hp_p hp_weights\n",
       "0             sklearn.neighbors._regression  KNeighborsRegressor     0.8411    0.7797  0.0614      True         auto            30  minkowski             None      None               5     2    uniform"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn_summary Works! #\n",
    "#!# coefficients need to go on the other side. params after that.\n",
    "model_type = KNeighborsRegressor()\n",
    "\n",
    "summary.knn_summary(x = x_data,\n",
    "                    y = y_data,\n",
    "                    model = model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d3d176c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function quick_lm in module baserush.optimize:\n",
      "\n",
      "quick_lm(x_data: 'pd.DataFrame', y_data: 'Union[pd.Series, np.ndarray, List[float]]', force_in: 'list' = None, threshold_in: 'float' = 0.01, threshold_out: 'float' = 0.05, max_iter: 'int' = 100, verbose: 'bool' = True) -> 'List[str]'\n",
      "    Builds a linear model using stepwise feature selection based on\n",
      "    p-values, returning a list of optimal x-features.\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    x_data : pandas.DataFrame\n",
      "        DataFrame with candidate features.\n",
      "    y_data : array-like\n",
      "        The target variable.\n",
      "    force_in : list\n",
      "        X-feature(s) to force into the model.\n",
      "    threshold_in : float\n",
      "        Include a feature if its p-value < threshold_in.\n",
      "    threshold_out : float\n",
      "        Exclude a feature if its p-value > threshold_out.\n",
      "    verbose : bool\n",
      "        Whether to print the sequence of inclusions and exclusions.\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    list\n",
      "        The list of selected features.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    - Ensure `threshold_in < threshold_out` for stable behavior.\n",
      "    - If a candidate leads to singular fits or other errors, it is treated as non-significant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## optimizer ##\n",
    "help(optimize.quick_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "166777d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  Total_Bsmt_SF                  with p-value 0.0\n",
      "Add  Gr_Liv_Area                    with p-value 6.58941e-302\n",
      "Add  Garage_Area                    with p-value 6.86611e-101\n",
      "Add  Neighborhood_NridgHt           with p-value 5.36792e-60\n",
      "Add  Neighborhood_OldTown           with p-value 3.01986e-25\n",
      "Add  Neighborhood_NAmes             with p-value 4.45149e-17\n",
      "Add  Mas_Vnr_Area                   with p-value 1.09564e-16\n",
      "Add  Neighborhood_Edwards           with p-value 5.93337e-15\n",
      "Add  Porch_Area                     with p-value 9.81431e-13\n",
      "Add  Neighborhood_Somerst           with p-value 1.46863e-12\n",
      "Add  Lot_Config_CulDSac             with p-value 1.75549e-10\n",
      "Add  Neighborhood_NWAmes            with p-value 9.88008e-10\n",
      "Add  Neighborhood_Sawyer            with p-value 3.78137e-09\n",
      "Add  log_Lot_Area                   with p-value 3.3191e-10\n",
      "Add  Neighborhood_Mitchel           with p-value 1.76138e-08\n",
      "Add  Neighborhood_BrkSide           with p-value 8.92562e-07\n",
      "Add  Neighborhood_SawyerW           with p-value 0.000250425\n",
      "Add  Lot_Area                       with p-value 0.000874396\n",
      "Add  Lot_Config_Corner              with p-value 0.0501316\n",
      "Add  Neighborhood_Crawfor           with p-value 0.17317\n",
      "Add  Neighborhood_CollgCr           with p-value 0.267794\n",
      "Add  First_Flr_SF                   with p-value 0.31821\n",
      "Add  Second_Flr_SF                  with p-value 0.0138304\n",
      "Add  log_Gr_Liv_Area                with p-value 0.323256\n",
      "Add  m_Mas_Vnr_Area                 with p-value 0.590428\n",
      "Add  m_Second_Flr_SF                with p-value 0.72652\n",
      "Add  Neighborhood_Gilbert           with p-value 0.835803\n",
      "Add  m_Lot_Area                     with p-value 0.871333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Total_Bsmt_SF',\n",
       " 'Gr_Liv_Area',\n",
       " 'Garage_Area',\n",
       " 'Neighborhood_NridgHt',\n",
       " 'Neighborhood_OldTown',\n",
       " 'Neighborhood_NAmes',\n",
       " 'Mas_Vnr_Area',\n",
       " 'Neighborhood_Edwards',\n",
       " 'Porch_Area',\n",
       " 'Neighborhood_Somerst',\n",
       " 'Lot_Config_CulDSac',\n",
       " 'Neighborhood_NWAmes',\n",
       " 'Neighborhood_Sawyer',\n",
       " 'log_Lot_Area',\n",
       " 'Neighborhood_Mitchel',\n",
       " 'Neighborhood_BrkSide',\n",
       " 'Neighborhood_SawyerW',\n",
       " 'Lot_Area',\n",
       " 'Lot_Config_Corner',\n",
       " 'Neighborhood_Crawfor',\n",
       " 'Neighborhood_CollgCr',\n",
       " 'First_Flr_SF',\n",
       " 'Second_Flr_SF',\n",
       " 'log_Gr_Liv_Area',\n",
       " 'm_Mas_Vnr_Area',\n",
       " 'm_Second_Flr_SF',\n",
       " 'Neighborhood_Gilbert',\n",
       " 'm_Lot_Area']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works!\n",
    "optimize.quick_lm(x_data = x_data,\n",
    "                  y_data = y_data,\n",
    "                  threshold_in  = 0.90,\n",
    "                  threshold_out = 1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78015d0f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tuning_results in module baserush.optimize:\n",
      "\n",
      "tuning_results(cv_results: 'Union[Mapping[str, Any], Any]', n: 'int' = 1, round_digits: 'int' = 6) -> 'pd.DataFrame'\n",
      "    Extracts the top-n hyperparameter tuning results from sklearn model\n",
      "    selection tools (GridSearchCV or RandomizedSearchCV). Outputs an organized\n",
      "    DataFrame containing:\n",
      "        * Model Rank       (rank_test_score)\n",
      "        * Mean Test Score  (mean_test_score)\n",
      "        * StDev Test Score (std_test_score)\n",
      "        * Best Parameters  (best_params)\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    cv_results : dict or fitted search object\n",
      "        Either the dictionary from `.cv_results_` or a fitted GridSearchCV /\n",
      "        RandomizedSearchCV object (the function will read `.cv_results_` if\n",
      "        present).\n",
      "    n : int, default=1\n",
      "        The number of top ranks to include. All rows with rank_test_score <= n\n",
      "        are returned (i.e., ties are included).\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    pd.DataFrame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tuning results\n",
    "help(optimize.tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d28f7b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function quick_tree in module baserush.optimize:\n",
      "\n",
      "quick_tree(x_data, y_data: 'Sequence[float]', model_type: 'Callable[..., object]' = None, max_leaf_samples: 'int' = 50, leaf_values: 'Optional[Sequence[int]]' = None, max_depth: 'int' = 20, depths: 'Optional[Sequence[int]]' = None, cv_folds: 'int' = 3, n: 'int' = 5, random_state: 'int' = 702) -> 'pd.DataFrame'\n",
      "    Quickly tunes a tree-based model using a two-stage cross-validated\n",
      "    procedure. Often returns multiple trees since multiple metrics are used in\n",
      "    evaluating which tree is \"best\".\n",
      "\n",
      "    PARAMETERS\n",
      "    ----------\n",
      "    x_data            | array-like | feature matrix                               | No default\n",
      "    y_data            | array-like | target vector                                | No default\n",
      "    model_type        | model      | tree-based model type                        | Default = DTree (Reg)\n",
      "    max_leaf_samples  | int        | largest min_samples_leaf if leaf_values None | Default = 50\n",
      "    leaf_values       | seq[int]   | explicit set of min_samples_leaf candidates  | Default = None\n",
      "    max_depth         | int        | largest depth tested if depths None          | Default = 20\n",
      "    depths            | seq[int]   | explicit set of depths to evaluate           | Default = None\n",
      "    cv_folds          | int        | number of CV folds                           | Default = 3\n",
      "    n                 | int        | top-n unique per metric (no ties beyond n)   | Default = 5\n",
      "    random_state      | int        | RNG seed for KFold and models                | Default = 702\n",
      "\n",
      "    RETURNS\n",
      "    -------\n",
      "    DataFrame with:\n",
      "      * depth\n",
      "      * min_samples_leaf\n",
      "      * folds\n",
      "      * mean_RSS\n",
      "      * mean_R2\n",
      "      * RSS_range (max_RSS - min_RSS across folds)\n",
      "      * R2_range  (max_R2  - min_R2  across folds)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick_tree\n",
    "help(optimize.quick_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e89584b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>folds</th>\n",
       "      <th>mean_RSS</th>\n",
       "      <th>mean_R2</th>\n",
       "      <th>RSS_range</th>\n",
       "      <th>R2_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>246.245629</td>\n",
       "      <td>0.746825</td>\n",
       "      <td>9.026462</td>\n",
       "      <td>0.039688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>265.497541</td>\n",
       "      <td>0.727231</td>\n",
       "      <td>0.560701</td>\n",
       "      <td>0.032879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>308.339876</td>\n",
       "      <td>0.684127</td>\n",
       "      <td>43.842228</td>\n",
       "      <td>0.012473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  min_samples_leaf  folds    mean_RSS   mean_R2  RSS_range  R2_range\n",
       "0      8                13      3  246.245629  0.746825   9.026462  0.039688\n",
       "1      7                27      3  265.497541  0.727231   0.560701  0.032879\n",
       "2      8                50      3  308.339876  0.684127  43.842228  0.012473"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.quick_tree(x_data           = x_data,\n",
    "                    y_data           = y_data,\n",
    "                    max_leaf_samples = 50,\n",
    "                    max_depth        = 20,\n",
    "                    n                = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02073294",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The optimal number of neighbors is 9.\n",
      "    Training R-Square: 0.8097\n",
      "    Testing  R-Square: 0.7953\n",
      "    Train-Test Gap:    0.0145\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\">?<span>Documentation for KNeighborsRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsRegressor(n_neighbors=50)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.quick_neighbors(x_data = x_data,\n",
    "                         y_data = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a727c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58dc56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bde91c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "19\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# developing hyperparameter ranges\n",
    "criterion_range = [\"squared_error\", \"friedman_mse\", \"absolute_error\", 'poisson']\n",
    "splitter_range  = ['best', 'random']    # splitter\n",
    "depth_range     = np.arange(1, 20, 1)   # max_depth\n",
    "leaf_range      = np.arange(.001, .101, .001)\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_gr = {'criterion'        : criterion_range,\n",
    "            'splitter'         : splitter_range,\n",
    "            'max_depth'        : depth_range,\n",
    "            'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# checking number of values per key\n",
    "for key, value in param_gr.items():\n",
    "    print(len(value))\n",
    "\n",
    "\n",
    "param_grid = ParameterGrid(param_grid=param_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1c597",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model_type = DecisionTreeRegressor(max_depth = 20,\n",
    "                                   random_state = 702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea7eab",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def tree_depth_sweep(X, y, max_depth=20, random_state=702):\n",
    "    \"\"\"\n",
    "    Trains DecisionTreeRegressor models for depths 1..max_depth (inclusive),\n",
    "    and returns a DataFrame with depth, RSS, and R^2 computed on the given X,y.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for d in range(1, max_depth + 1):\n",
    "        model = DecisionTreeRegressor(max_depth=d, random_state=random_state)\n",
    "        model.fit(X, y)\n",
    "        y_hat = model.predict(X)\n",
    "        rss = np.sum((y - y_hat) ** 2)\n",
    "        r2  = model.score(X, y)\n",
    "        rows.append({\"depth\": d, \"RSS\": rss, \"R2\": r2})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- Example usage ---\n",
    "# Your model template:\n",
    "max_model = DecisionTreeRegressor(max_depth=20, random_state=702)\n",
    "\n",
    "\n",
    "# Run the sweep using its settings\n",
    "results = tree_depth_sweep(X            = x_data,\n",
    "                           y            = y_data,\n",
    "                           max_depth    = max_model.max_depth,\n",
    "                           random_state = model_type.random_state)\n",
    "\n",
    "# View the simple table\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "522d549a",
   "metadata": {
    "code_folding": [
     7,
     13,
     71,
     76
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth  folds    mean_RSS   mean_R2  RSS_range  R2_range\n",
      "0       1      3  694.185887  0.288107  62.914734  0.021575\n",
      "1       2      3  459.822657  0.527749  68.763555  0.090473\n",
      "2       3      3  373.986221  0.616754  47.676047  0.002576\n",
      "3       4      3  298.075389  0.693868   5.257352  0.031564\n",
      "4       5      3  268.667739  0.724111  11.359621  0.026451\n",
      "5       6      3  265.535536  0.727572  24.268221  0.022336\n",
      "6       7      3  273.357616  0.720226  52.077896  0.019352\n",
      "7       8      3  296.605917  0.695664  57.312126  0.057107\n",
      "8       9      3  316.858376  0.675552  85.499706  0.066354\n",
      "9      10      3  337.782181  0.653259  63.748334  0.071424\n",
      "10     11      3  319.744929  0.670695  55.330174  0.079720\n",
      "11     12      3  332.060125  0.659121  59.151285  0.067273\n",
      "12     13      3  340.845615  0.650405  48.512799  0.041400\n",
      "13     14      3  354.950252  0.635839  63.366048  0.061069\n",
      "14     15      3  358.947365  0.632165  83.909695  0.062427\n",
      "15     16      3  357.690898  0.633173  73.499591  0.063875\n",
      "16     17      3  354.958263  0.635388  47.220481  0.067253\n",
      "17     18      3  336.123638  0.654546  20.591142  0.047851\n",
      "18     19      3  338.041810  0.652070  37.743580  0.073201\n",
      "19     20      3  354.171556  0.635199  44.151251  0.090071\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def tree_depth_cv_sweep(\n",
    "    X,\n",
    "    y: Sequence[float],\n",
    "    max_depth: int = 20,\n",
    "    cv_folds: int = 3,\n",
    "    random_state: int = 702,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains DecisionTreeRegressor models for depths 1..max_depth (inclusive),\n",
    "    evaluates with K-fold CV, and returns a table with depth-wise statistics.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    X            | array-like | feature matrix                               | No default\n",
    "    y            | array-like | target vector                                | No default\n",
    "    max_depth    | int        | largest tree depth to test                   | Default = 20\n",
    "    cv_folds     | int        | number of folds for CV (even split intent)   | Default = 3\n",
    "    random_state | int        | RNG seed for reproducibility (CV + model)    | Default = 702\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    A DataFrame with:\n",
    "      * depth\n",
    "      * folds\n",
    "      * mean_RSS\n",
    "      * mean_R2\n",
    "      * RSS_range (max_RSS - min_RSS across folds)\n",
    "      * R2_range  (max_R2  - min_R2  across folds)\n",
    "    \"\"\"\n",
    "    y = np.asarray(y).ravel()\n",
    "    rows = []\n",
    "\n",
    "    # Even-ish splits via KFold (sizes differ by at most 1 if not divisible)\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for d in range(1, max_depth + 1):\n",
    "        rss_scores = []\n",
    "        r2_scores  = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            model = DecisionTreeRegressor(max_depth=d, random_state=random_state)\n",
    "            model.fit(np.asarray(X)[train_idx], y[train_idx])\n",
    "\n",
    "            y_val  = y[val_idx]\n",
    "            y_pred = model.predict(np.asarray(X)[val_idx])\n",
    "\n",
    "            rss = np.sum((y_val - y_pred) ** 2)      # Residual Sum of Squares on the fold\n",
    "            r2  = r2_score(y_val, y_pred)            # R² on the fold\n",
    "\n",
    "            rss_scores.append(rss)\n",
    "            r2_scores.append(r2)\n",
    "\n",
    "        rows.append({\n",
    "            \"depth\": d,\n",
    "            \"folds\": cv_folds,\n",
    "            \"mean_RSS\": float(np.mean(rss_scores)),\n",
    "            \"mean_R2\":  float(np.mean(r2_scores)),\n",
    "            \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "            \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "# Model template (as provided)\n",
    "model_type = DecisionTreeRegressor(max_depth=20, random_state=702)\n",
    "\n",
    "# Run the sweep (uses validation metrics from K-fold CV)\n",
    "results = tree_depth_cv_sweep(\n",
    "    X            = x_data,\n",
    "    y            = y_data,\n",
    "    max_depth    = model_type.max_depth,\n",
    "    cv_folds     = 3,                    # <— change if you want more/less folds\n",
    "    random_state = model_type.random_state\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764567b",
   "metadata": {},
   "source": [
    "Based on below, I want to build a set of the top five winners in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb79e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results.sort_values(by = 'mean_RSS', ascending = True)   # 6, 5, 4, 7, 3\n",
    "#results.sort_values(by = 'mean_R2' , ascending = False)  # 6, 5, 4, 7, 3\n",
    "#results.sort_values(by = 'RSS_range' , ascending = True) # 4, 3, 5, 2, 6\n",
    "#results.sort_values(by = 'R2_range' , ascending = True)  # 2, 3, 0, 5, 4\n",
    "\n",
    "#set([6, 5, 4, 7, 3, 6, 5, 4, 7, 3, 4, 3, 5, 2, 6, 2, 3, 0, 5, 4])\n",
    "\n",
    "results.loc[ [6, 5, 4, 7, 3, 2, 0] , : ].sort_values(by = 'depth')\n",
    "\n",
    "depth_values = list(results.loc[ [6, 5, 4, 7, 3, 2, 0], 'depth'])\n",
    "depth_values.sort()\n",
    "depth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "526a5b13",
   "metadata": {
    "code_folding": [
     7,
     14
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence, Optional\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def tree_leaf_cv_sweep(\n",
    "    X,\n",
    "    y: Sequence[float],\n",
    "    max_leaf_samples: int = 20,\n",
    "    leaf_values: Optional[Sequence[int]] = None,\n",
    "    cv_folds: int = 3,\n",
    "    random_state: int = 702,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains DecisionTreeRegressor models across min_samples_leaf values and\n",
    "    evaluates with K-fold CV. Returns a table with leaf-wise statistics.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    X                | array-like | feature matrix                               | No default\n",
    "    y                | array-like | target vector                                | No default\n",
    "    max_leaf_samples | int        | largest min_samples_leaf to test (1..N)      | Default = 20\n",
    "    leaf_values      | sequence   | explicit list of min_samples_leaf values     | Default = None\n",
    "    cv_folds         | int        | number of folds for CV                       | Default = 3\n",
    "    random_state     | int        | RNG seed for reproducibility                  | Default = 702\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    A DataFrame with:\n",
    "      * min_samples_leaf\n",
    "      * folds\n",
    "      * mean_RSS\n",
    "      * mean_R2\n",
    "      * RSS_range (max_RSS - min_RSS across folds)\n",
    "      * R2_range  (max_R2  - min_R2  across folds)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).ravel()\n",
    "\n",
    "    # Build the grid of min_samples_leaf values to test\n",
    "    if leaf_values is None:\n",
    "        leaf_values = range(1, max_leaf_samples + 1)\n",
    "\n",
    "    rows = []\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for leaf in leaf_values:\n",
    "        rss_scores = []\n",
    "        r2_scores  = []\n",
    "\n",
    "        #!# specifies the model directly instead of having it as a parameter. Change this.\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            model = DecisionTreeRegressor(\n",
    "                min_samples_leaf=leaf,\n",
    "                random_state=random_state\n",
    "            )\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "            y_val  = y[val_idx]\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "\n",
    "            rss = np.sum((y_val - y_pred) ** 2)\n",
    "            r2  = r2_score(y_val, y_pred)\n",
    "\n",
    "            rss_scores.append(rss)\n",
    "            r2_scores.append(r2)\n",
    "\n",
    "        rows.append({\n",
    "            \"min_samples_leaf\": int(leaf),\n",
    "            \"folds\": cv_folds,\n",
    "            \"mean_RSS\": float(np.mean(rss_scores)),\n",
    "            \"mean_R2\":  float(np.mean(r2_scores)),\n",
    "            \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "            \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "277ea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example usage ---\n",
    "# Matches your original template style, but now sweeping min_samples_leaf\n",
    "model_type = DecisionTreeRegressor(random_state=702) #!# add in max_leaf_samples as a parameter\n",
    "\n",
    "results_leaf = tree_leaf_cv_sweep(\n",
    "    X = x_data,\n",
    "    y = y_data,\n",
    "    max_leaf_samples= 200,                 # or pass leaf_values=[1,2,5,10,20] etc.\n",
    "    cv_folds=3,\n",
    "    random_state=model_type.random_state\n",
    ")\n",
    "\n",
    "#print(results_leaf.sort_values(by = 'mean_RSS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9992600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     min_samples_leaf  folds    mean_RSS   mean_R2   RSS_range  R2_range\n",
      "12                 13      3  247.844303  0.745187    8.783475  0.039630\n",
      "18                 19      3  248.659639  0.744556    6.683199  0.029495\n",
      "16                 17      3  249.129709  0.743930   15.383089  0.036632\n",
      "15                 16      3  249.252269  0.743877   11.154003  0.033029\n",
      "19                 20      3  249.839616  0.743345    7.108816  0.029537\n",
      "11                 12      3  250.013151  0.743193    7.653478  0.028293\n",
      "17                 18      3  250.867397  0.742265    4.913497  0.030898\n",
      "20                 21      3  251.031534  0.741991    7.800641  0.036152\n",
      "21                 22      3  251.295722  0.741644    8.541786  0.039927\n",
      "14                 15      3  252.925904  0.739854   14.182334  0.045866\n",
      "9                  10      3  253.848123  0.738956   18.625156  0.043561\n",
      "13                 14      3  254.106011  0.738809   17.529880  0.037663\n",
      "10                 11      3  254.823642  0.737993   20.427946  0.041723\n",
      "22                 23      3  256.341871  0.736546    8.977039  0.036249\n",
      "29                 30      3  260.435440  0.732588    7.616683  0.024460\n",
      "24                 25      3  261.788131  0.730846   13.385015  0.042133\n",
      "8                   9      3  261.689491  0.730793   26.563409  0.049831\n",
      "6                   7      3  261.926713  0.730258   32.831321  0.064358\n",
      "25                 26      3  262.866201  0.729953    2.786568  0.031608\n",
      "28                 29      3  263.101549  0.729760    4.257980  0.029235\n",
      "23                 24      3  263.061914  0.729707    6.776818  0.033837\n",
      "26                 27      3  263.789662  0.728970    0.690739  0.033455\n",
      "30                 31      3  265.182150  0.727933   18.406514  0.014020\n",
      "27                 28      3  265.145113  0.727559    1.781925  0.034543\n",
      "31                 32      3  268.877169  0.724091   15.978671  0.016751\n",
      "32                 33      3  268.890939  0.724053   14.785818  0.017967\n",
      "7                   8      3  268.216999  0.724025   19.583230  0.053697\n",
      "33                 34      3  272.062289  0.720785   20.990025  0.023224\n",
      "34                 35      3  275.459201  0.717388   18.651787  0.016493\n",
      "36                 37      3  276.342564  0.716523   20.705954  0.015471\n",
      "35                 36      3  276.460291  0.716376   21.334202  0.018532\n",
      "38                 39      3  276.943233  0.715794   21.990469  0.023406\n",
      "37                 38      3  277.553353  0.715228   21.231214  0.019721\n",
      "39                 40      3  278.287511  0.714433   24.275468  0.024913\n",
      "41                 42      3  279.069430  0.713495   22.952987  0.030087\n",
      "40                 41      3  279.414498  0.713294   23.051117  0.022774\n",
      "5                   6      3  279.312229  0.712218   39.550329  0.075328\n",
      "4                   5      3  287.800992  0.703559   35.823514  0.073313\n",
      "42                 43      3  289.563375  0.702773   13.030639  0.022600\n",
      "3                   4      3  295.044841  0.697291   30.911841  0.029255\n",
      "45                 46      3  295.778702  0.696538   19.971971  0.015849\n",
      "43                 44      3  296.503146  0.695765   21.393180  0.020675\n",
      "44                 45      3  296.955851  0.695334   22.305050  0.020011\n",
      "46                 47      3  299.364881  0.692822   26.089735  0.025895\n",
      "47                 48      3  302.107581  0.690158   27.548539  0.020116\n",
      "48                 49      3  304.702371  0.687638   32.772038  0.014806\n",
      "49                 50      3  308.309295  0.684160   43.933969  0.012573\n",
      "50                 51      3  309.530839  0.682925   44.676215  0.018680\n",
      "52                 53      3  311.281553  0.681061   41.540269  0.016031\n",
      "51                 52      3  311.432814  0.680872   39.942914  0.014775\n",
      "2                   3      3  313.038541  0.679391   60.009966  0.041045\n",
      "53                 54      3  315.134011  0.677285   50.494278  0.016612\n",
      "54                 55      3  317.774972  0.674425   43.523099  0.010059\n",
      "57                 58      3  318.101486  0.674143   46.024422  0.013359\n",
      "56                 57      3  318.212091  0.674020   45.566085  0.012895\n",
      "58                 59      3  318.214462  0.674009   45.082130  0.015165\n",
      "55                 56      3  318.716378  0.673496   45.279239  0.013096\n",
      "59                 60      3  319.605452  0.672518   42.178346  0.011069\n",
      "60                 61      3  320.452510  0.671608   40.258862  0.009598\n",
      "61                 62      3  321.022513  0.671019   40.034836  0.011512\n",
      "62                 63      3  321.138562  0.670900   40.037831  0.011324\n",
      "63                 64      3  321.433776  0.670591   39.767033  0.010573\n",
      "64                 65      3  322.360157  0.669649   40.161177  0.013142\n",
      "65                 66      3  323.677202  0.668374   44.005183  0.013098\n",
      "66                 67      3  323.778197  0.668269   43.939861  0.013274\n",
      "67                 68      3  325.214455  0.666790   43.924200  0.008893\n",
      "68                 69      3  328.208135  0.663721   43.990602  0.016620\n",
      "71                 72      3  328.491706  0.663417   43.371256  0.016181\n",
      "72                 73      3  328.537941  0.663367   43.253556  0.016074\n",
      "69                 70      3  328.746096  0.663160   43.521337  0.017281\n",
      "70                 71      3  328.852656  0.663047   43.362859  0.017273\n",
      "74                 75      3  329.285837  0.662598   43.087857  0.019113\n",
      "75                 76      3  329.374214  0.662499   42.713976  0.018594\n",
      "80                 81      3  329.481463  0.662302   38.492815  0.018237\n",
      "73                 74      3  329.742096  0.662114   42.406689  0.017995\n",
      "77                 78      3  330.104443  0.661707   40.745124  0.016547\n",
      "79                 80      3  330.148618  0.661677   41.450453  0.017955\n",
      "76                 77      3  330.379531  0.661406   39.838715  0.015602\n",
      "86                 87      3  329.896660  0.661287   45.939835  0.056520\n",
      "78                 79      3  330.543731  0.661229   39.479085  0.015069\n",
      "81                 82      3  332.592345  0.659057   41.746038  0.026092\n",
      "85                 86      3  333.863615  0.657642   36.185841  0.025629\n",
      "84                 85      3  334.008837  0.657502   36.185420  0.025208\n",
      "83                 84      3  334.265301  0.657231   35.633630  0.024998\n",
      "88                 89      3  333.984524  0.656835   37.387489  0.057088\n",
      "82                 83      3  334.673014  0.656805   35.498842  0.025260\n",
      "89                 90      3  334.144812  0.656673   37.477648  0.057190\n",
      "87                 88      3  334.927781  0.655823   37.890857  0.057609\n",
      "90                 91      3  335.722703  0.654872   34.471858  0.054096\n",
      "93                 94      3  336.713155  0.653645   28.526858  0.062523\n",
      "92                 93      3  337.282560  0.653066   29.702177  0.062266\n",
      "94                 95      3  337.819956  0.652504   26.913193  0.062825\n",
      "96                 97      3  338.732397  0.651625   25.157114  0.060045\n",
      "91                 92      3  338.905606  0.651403   34.571317  0.062266\n",
      "95                 96      3  339.130743  0.651213   26.181754  0.060231\n",
      "97                 98      3  339.279710  0.651104   23.636995  0.058077\n",
      "106               107      3  340.864976  0.649784   22.727858  0.042904\n",
      "103               104      3  340.833216  0.649779   26.729609  0.046761\n",
      "98                 99      3  341.293435  0.649040   29.678170  0.058077\n",
      "99                100      3  341.980861  0.648333   31.111009  0.058197\n",
      "104               105      3  342.409169  0.648173   30.502816  0.050657\n",
      "105               106      3  342.441000  0.648141   30.624982  0.050782\n",
      "100               101      3  342.673754  0.647664   29.021844  0.056166\n",
      "101               102      3  342.769708  0.647562   29.151242  0.056339\n",
      "1                   2      3  344.437955  0.646788   50.881376  0.040279\n",
      "102               103      3  343.593205  0.646661   29.215526  0.059166\n",
      "110               111      3  347.810729  0.643041   22.814976  0.025713\n",
      "109               110      3  347.973821  0.642916   21.151449  0.022177\n",
      "108               109      3  349.928943  0.641025   25.822268  0.016539\n",
      "107               108      3  350.181578  0.640780   26.502674  0.015881\n",
      "112               113      3  361.745054  0.628815   61.966304  0.062987\n",
      "113               114      3  361.961775  0.628592   62.531440  0.063610\n",
      "114               115      3  361.961775  0.628592   62.531440  0.063610\n",
      "111               112      3  362.151553  0.628415   61.778255  0.061990\n",
      "117               118      3  362.399151  0.628180   62.259076  0.061574\n",
      "116               117      3  362.455295  0.628118   62.067572  0.061562\n",
      "115               116      3  362.549611  0.628023   62.504101  0.061932\n",
      "118               119      3  364.622886  0.625859   58.449759  0.059485\n",
      "119               120      3  366.165061  0.624278   63.076284  0.064227\n",
      "120               121      3  366.277768  0.624167   63.811896  0.064777\n",
      "121               122      3  367.940401  0.622369   59.200032  0.064414\n",
      "0                   1      3  368.889934  0.621185   74.187786  0.089759\n",
      "123               124      3  373.529582  0.616271   42.227049  0.064309\n",
      "122               123      3  373.555861  0.616245   42.353650  0.064414\n",
      "124               125      3  378.978391  0.610594   54.370264  0.076772\n",
      "125               126      3  389.018121  0.600829   53.206894  0.053804\n",
      "126               127      3  389.075880  0.600766   53.033616  0.053804\n",
      "127               128      3  389.144551  0.600700   53.033616  0.053605\n",
      "128               129      3  389.169405  0.600673   52.959053  0.053605\n",
      "129               130      3  390.471031  0.599415   52.965973  0.049824\n",
      "130               131      3  391.911955  0.597843   48.643200  0.049824\n",
      "132               133      3  392.094122  0.597656   49.205324  0.050415\n",
      "131               132      3  392.127753  0.597622   49.290594  0.050488\n",
      "134               135      3  392.486765  0.597259   50.749223  0.051772\n",
      "133               134      3  392.564536  0.597174   50.607405  0.051844\n",
      "135               136      3  392.601803  0.597167   51.228723  0.050975\n",
      "136               137      3  392.760547  0.597002   50.953603  0.050780\n",
      "139               140      3  393.342481  0.596448   50.570040  0.048291\n",
      "138               139      3  393.475756  0.596311   50.953603  0.048706\n",
      "137               138      3  393.475756  0.596311   50.953603  0.048706\n",
      "140               141      3  394.393393  0.595395   52.655571  0.049220\n",
      "142               143      3  395.421346  0.594411   52.872253  0.046030\n",
      "141               142      3  395.435625  0.594395   52.829419  0.046030\n",
      "146               147      3  395.722321  0.594107   54.263434  0.047245\n",
      "145               146      3  395.731134  0.594098   54.263434  0.047219\n",
      "147               148      3  395.880414  0.593954   54.263434  0.046786\n",
      "148               149      3  395.910121  0.593922   54.174315  0.046786\n",
      "144               145      3  396.019792  0.593795   54.477919  0.047773\n",
      "143               144      3  396.829202  0.592966   56.909334  0.050263\n",
      "149               150      3  399.930171  0.589759   62.412334  0.057189\n",
      "150               151      3  399.930171  0.589759   62.412334  0.057189\n",
      "151               152      3  399.930171  0.589759   62.412334  0.057189\n",
      "152               153      3  399.930171  0.589759   62.412334  0.057189\n",
      "153               154      3  399.930171  0.589759   62.412334  0.057189\n",
      "154               155      3  400.024240  0.589668   62.412334  0.056917\n",
      "155               156      3  400.024240  0.589668   62.412334  0.056917\n",
      "156               157      3  400.024240  0.589668   62.412334  0.056917\n",
      "161               162      3  403.115985  0.586731   59.699132  0.042656\n",
      "158               159      3  403.922912  0.585900   62.412334  0.045612\n",
      "157               158      3  403.922912  0.585900   62.412334  0.045612\n",
      "159               160      3  404.000376  0.585825   62.399668  0.045400\n",
      "160               161      3  404.008269  0.585816   62.375987  0.045400\n",
      "165               166      3  404.753812  0.585053   64.676695  0.047727\n",
      "164               165      3  404.756801  0.585049   64.668723  0.047726\n",
      "163               164      3  404.763262  0.585042   64.649338  0.047726\n",
      "162               163      3  404.764658  0.585041   64.645152  0.047726\n",
      "169               170      3  404.912859  0.584875   63.586429  0.047282\n",
      "168               169      3  404.930118  0.584862   64.076922  0.047562\n",
      "167               168      3  404.956379  0.584835   64.155707  0.047643\n",
      "166               167      3  404.956379  0.584835   64.155707  0.047643\n",
      "170               171      3  431.334652  0.557782  141.973422  0.128082\n",
      "171               172      3  435.283481  0.553564  132.265099  0.126016\n",
      "172               173      3  435.283481  0.553564  132.265099  0.126016\n",
      "173               174      3  435.351499  0.553498  132.265099  0.125819\n",
      "188               189      3  442.590979  0.546555  134.431077  0.112954\n",
      "189               190      3  442.719788  0.546415  134.044649  0.112533\n",
      "174               175      3  442.746611  0.546358  132.444166  0.110826\n",
      "178               179      3  442.834520  0.546262  132.180438  0.110538\n",
      "179               180      3  442.834520  0.546262  132.180438  0.110538\n",
      "177               178      3  442.834520  0.546262  132.180438  0.110538\n",
      "176               177      3  442.834520  0.546262  132.180438  0.110538\n",
      "175               176      3  442.834520  0.546262  132.180438  0.110538\n",
      "181               182      3  442.864102  0.546234  132.180438  0.110538\n",
      "180               181      3  442.864102  0.546234  132.180438  0.110538\n",
      "182               183      3  442.874324  0.546223  132.149770  0.110505\n",
      "183               184      3  442.951095  0.546139  131.919458  0.110254\n",
      "187               188      3  443.362925  0.545726  132.421798  0.110763\n",
      "184               185      3  443.357934  0.545722  133.139976  0.111505\n",
      "185               186      3  443.357934  0.545722  133.139976  0.111505\n",
      "186               187      3  443.378882  0.545699  133.077131  0.111436\n",
      "190               191      3  444.082068  0.545018  138.138197  0.116729\n",
      "199               200      3  444.184514  0.544919  138.159004  0.116750\n",
      "196               197      3  444.431979  0.544680  138.138197  0.116729\n",
      "197               198      3  444.431979  0.544680  138.138197  0.116729\n",
      "195               196      3  444.481271  0.544632  138.138197  0.116729\n",
      "198               199      3  444.489934  0.544624  138.138197  0.116729\n",
      "192               193      3  444.545596  0.544570  138.138197  0.116729\n",
      "191               192      3  444.554049  0.544562  138.138197  0.116729\n",
      "193               194      3  444.684777  0.544436  138.138197  0.116729\n",
      "194               195      3  444.720583  0.544401  138.138197  0.116729\n"
     ]
    }
   ],
   "source": [
    "print(results_leaf.sort_values(by = 'mean_R2', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ec57d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 12, 13, 14, 15, 16, 17, 19, 20, 29, 30, 33]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_leaf.sort_values(by = 'mean_RSS', ascending = True)    # 11, 18, 19, 12, 16\n",
    "#results_leaf.sort_values(by = 'mean_R2' , ascending = False)   # 11, 18, 19, 12, 16 \n",
    "#results_leaf.sort_values(by = 'RSS_range' , ascending = True)  # 14, 11, 7, 13, 32\n",
    "#results_leaf.sort_values(by = 'R2_range' , ascending = True)   # 19, 18, 28, 15, 29\n",
    "\n",
    "#set([11, 18, 19, 12, 16, 11, 18, 19, 12, 16, 14, 11, 7, 13, 32, 19, 18, 28, 15, 29])\n",
    "\n",
    "results_leaf.loc[ [7, 11, 12, 13, 14, 15, 16, 18, 19, 28, 29, 32] , : ].sort_values(by = 'min_samples_leaf')\n",
    "\n",
    "leaf_values = list(results_leaf.loc[ [7, 11, 12, 13, 14, 15, 16, 18, 19, 28, 29, 32], 'min_samples_leaf'])\n",
    "leaf_values.sort()\n",
    "leaf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5339ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "366237ac",
   "metadata": {
    "code_folding": [
     0,
     9
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def tree_depth_leaf_cv_sweep(\n",
    "    X,\n",
    "    y: Sequence[float],\n",
    "    max_depth: int = 20,\n",
    "    max_leaf_samples: int = 20,\n",
    "    depths: Optional[Sequence[int]] = None,\n",
    "    leaf_values: Optional[Sequence[int]] = None,\n",
    "    cv_folds: int = 3,\n",
    "    random_state: int = 702,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains DecisionTreeRegressor models across combinations of max_depth and\n",
    "    min_samples_leaf, evaluates with K-fold CV, and returns a results table.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    X                | array-like | feature matrix                              | No default\n",
    "    y                | array-like | target vector                               | No default\n",
    "    max_depth        | int        | largest depth tested if depths not provided | Default = 20\n",
    "    max_leaf_samples | int        | largest min_samples_leaf if none provided   | Default = 20\n",
    "    depths           | sequence   | explicit list of depths to test             | Default = None\n",
    "    leaf_values      | sequence   | explicit list of min_samples_leaf values    | Default = None\n",
    "    cv_folds         | int        | number of folds for CV                      | Default = 3\n",
    "    random_state     | int        | RNG seed for reproducibility                | Default = 702\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    A DataFrame with columns:\n",
    "      * depth\n",
    "      * min_samples_leaf\n",
    "      * folds\n",
    "      * mean_RSS\n",
    "      * mean_R2\n",
    "      * RSS_range  (max_RSS - min_RSS across folds)\n",
    "      * R2_range   (max_R2  - min_R2  across folds)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).ravel()\n",
    "\n",
    "    # Build grids if not provided\n",
    "    if depths is None:\n",
    "        depths = range(1, max_depth + 1)\n",
    "    if leaf_values is None:\n",
    "        leaf_values = range(1, max_leaf_samples + 1)\n",
    "\n",
    "    rows = []\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for d in depths:\n",
    "        for leaf in leaf_values:\n",
    "            rss_scores = []\n",
    "            r2_scores  = []\n",
    "\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                model = DecisionTreeRegressor(\n",
    "                    max_depth=d,\n",
    "                    min_samples_leaf=leaf,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "                y_val  = y[val_idx]\n",
    "                y_pred = model.predict(X[val_idx])\n",
    "\n",
    "                rss = float(np.sum((y_val - y_pred) ** 2))\n",
    "                r2  = float(r2_score(y_val, y_pred))\n",
    "\n",
    "                rss_scores.append(rss)\n",
    "                r2_scores.append(r2)\n",
    "\n",
    "            rows.append({\n",
    "                \"depth\": int(d),\n",
    "                \"min_samples_leaf\": int(leaf),\n",
    "                \"folds\": cv_folds,\n",
    "                \"mean_RSS\": float(np.mean(rss_scores)),\n",
    "                \"mean_R2\":  float(np.mean(r2_scores)),\n",
    "                \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "                \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "            })\n",
    "\n",
    "    results = pd.DataFrame(rows)\n",
    "    # Optional: sort for tidy display\n",
    "    #results = results.sort_values([\"depth\", \"min_samples_leaf\"]).reset_index(drop=True)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb5ccef3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# max grid (40-45 seconds)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results_grid \u001b[38;5;241m=\u001b[39m tree_depth_leaf_cv_sweep(\n\u001b[1;32m      3\u001b[0m     X \u001b[38;5;241m=\u001b[39m x_data,\n\u001b[1;32m      4\u001b[0m     y \u001b[38;5;241m=\u001b[39m y_data,\n\u001b[1;32m      5\u001b[0m     max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      6\u001b[0m     max_leaf_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m     cv_folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      8\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m702\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[33], line 60\u001b[0m, in \u001b[0;36mtree_depth_leaf_cv_sweep\u001b[0;34m(X, y, max_depth, max_leaf_samples, depths, leaf_values, cv_folds, random_state)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_idx, val_idx \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[1;32m     55\u001b[0m     model \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(\n\u001b[1;32m     56\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39md,\n\u001b[1;32m     57\u001b[0m         min_samples_leaf\u001b[38;5;241m=\u001b[39mleaf,\n\u001b[1;32m     58\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrandom_state\n\u001b[1;32m     59\u001b[0m     )\n\u001b[0;32m---> 60\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X[train_idx], y[train_idx])\n\u001b[1;32m     62\u001b[0m     y_val  \u001b[38;5;241m=\u001b[39m y[val_idx]\n\u001b[1;32m     63\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X[val_idx])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/e-sci/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/e-sci/lib/python3.12/site-packages/sklearn/tree/_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1378\u001b[0m         X,\n\u001b[1;32m   1379\u001b[0m         y,\n\u001b[1;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/e-sci/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# max grid (40-45 seconds)\n",
    "results_grid = tree_depth_leaf_cv_sweep(\n",
    "    X = x_data,\n",
    "    y = y_data,\n",
    "    max_depth = 20,\n",
    "    max_leaf_samples = 200,\n",
    "    cv_folds=3,\n",
    "    random_state=702\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_grid.sort_values(by = 'mean_RSS', ascending = True).head(n = 15)\n",
    "# depth: 9, 16, 17, 20, 19, 15, 14, 18\n",
    "# leaf : 12 ties eight times #!# need to consider ties\n",
    "# indexes: 1611, 3011, 3211, 3811, 3611, 2811, 2611, 3411\n",
    "\n",
    "#results_grid.sort_values(by = 'mean_R2' , ascending = False).head(n = 15)\n",
    "# depth: 9, 14, 19, 18, 15, 20, 16, 17\n",
    "# leaf : 12 ties eight times\n",
    "# indexes: 1611, 2611, 3611, 3411, 2811, 3811, 3011, 3211\n",
    "\n",
    "#results_grid.sort_values(by = 'RSS_range' , ascending = True).head(n = 15)\n",
    "# depth: 6, 5, 5, 6, 5\n",
    "# leaf : 11, 9, 10, 10, 11\n",
    "# indexes: 1010, 808, 809, 1009, 810\n",
    "\n",
    "#results_grid.sort_values(by = 'R2_range' , ascending = True).head(n = 15)\n",
    "# depth: 8, 3, 3, 8, 7, 7\n",
    "# leaf : 20, 1, 2, 19, 20, 19\n",
    "# indexes: 1419, 400, 401, 1418, 1219\n",
    "\n",
    "# # set of indexes\n",
    "# set([1611, 3011, 3211, 3811, 3611, 2811, 2611, 3411,\n",
    "#      1611, 2611, 3611, 3411, 2811, 3811, 3011, 3211,\n",
    "#      1010, 808, 809, 1009, 810,\n",
    "#      1419, 400, 401, 1418, 1219])\n",
    "\n",
    "# multi-parameter results (18 models)\n",
    "results_grid.loc[ [400, 401, 808, 809, 810, 1009, 1010, 1219, 1418, 1419,\n",
    "                   1611, 2611, 2811, 3011, 3211, 3411, 3611, 3811] , : ].sort_values(by = 'mean_RSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37822e01",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# putting the three sets together\n",
    "depth_res = results.loc[ [6, 5, 4, 7, 3, 2, 0] , : ].sort_values(by = 'depth')\n",
    "leaf_res  = results_leaf.loc[ [7, 11, 12, 13, 14, 15, 16, 18, 19, 28, 29, 32] , : ].sort_values(by = 'min_samples_leaf')\n",
    "multi_res = results_grid.loc[ [400, 401, 808, 809, 810, 1009, 1010, 1219, 1418, 1419,\n",
    "                               1611, 2611, 2811, 3011, 3211, 3411, 3611, 3811] , : ].sort_values(by = 'mean_RSS')\n",
    "\n",
    "\n",
    "# adding set identifier\n",
    "depth_res['set'] = 'depth'\n",
    "leaf_res['set']  = 'leaf'\n",
    "multi_res['set'] = 'multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5887c00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "all_results = pd.concat(objs = [multi_res, depth_res, leaf_res],\n",
    "                        axis = 0)\n",
    "\n",
    "\n",
    "# 28 unique rows\n",
    "len(all_results.drop_duplicates(subset = ['mean_RSS', 'mean_R2', 'RSS_range', 'R2_range'],\n",
    "                            keep = 'first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de95ea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# performance ties for the three approaches\n",
    "all_results[all_results[['mean_RSS', 'mean_R2', 'RSS_range', 'R2_range']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_values\n",
    "leaf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80960db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi not in depth:    9, 14, 15, 16, 17, 18, 19, 20\n",
    "# multi but not in leaf: 11, 10, 9, 2, 1\n",
    "\n",
    "### ranges! # nope, doesn't work :(\n",
    "# depth = range(1, 8+1)\n",
    "# leaf  = range(8, 33+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a872b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[all_results['set'] == 'multi'].sort_values(by = 'mean_R2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.sort_values(by = 'mean_R2', ascending = False)\n",
    "#results_leaf.sort_values(by = 'mean_R2', ascending = False)\n",
    "results_grid.sort_values(by = 'mean_R2', ascending = False).head(n = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368a476",
   "metadata": {},
   "source": [
    "## Testing Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence, Optional, Iterable, Set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def _cv_metrics_for_leaf(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    leaf: int,\n",
    "    cv_folds: int,\n",
    "    random_state: int\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Helper: compute CV metrics for a given min_samples_leaf value.\n",
    "    Returns a dict with mean_RSS, mean_R2, RSS_range, R2_range.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    rss_scores, r2_scores = [], []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        model = DecisionTreeRegressor(\n",
    "            min_samples_leaf=leaf,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        y_val  = y[val_idx]\n",
    "        y_pred = model.predict(X[val_idx])\n",
    "\n",
    "        rss_scores.append(float(np.sum((y_val - y_pred) ** 2)))\n",
    "        r2_scores.append(float(r2_score(y_val, y_pred)))\n",
    "\n",
    "    return {\n",
    "        \"min_samples_leaf\": int(leaf),\n",
    "        \"mean_RSS\":  float(np.mean(rss_scores)),\n",
    "        \"mean_R2\":   float(np.mean(r2_scores)),\n",
    "        \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "        \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "    }\n",
    "\n",
    "def _select_top_n_unique(\n",
    "    df: pd.DataFrame,\n",
    "    metric: str,\n",
    "    n: int,\n",
    "    direction: str\n",
    ") -> Iterable[int]:\n",
    "    \"\"\"\n",
    "    Helper: select the top-n unique min_samples_leaf values by a metric.\n",
    "    direction: 'lower' or 'higher'. Does NOT include ties beyond n.\n",
    "    Stable secondary sort by min_samples_leaf ascending for determinism.\n",
    "    \"\"\"\n",
    "    ascending = (direction == \"lower\")\n",
    "    ranked = df.sort_values([metric, \"min_samples_leaf\"], ascending=[ascending, True])\n",
    "    picked: Set[int] = set()\n",
    "    for _, row in ranked.iterrows():\n",
    "        leaf = int(row[\"min_samples_leaf\"])\n",
    "        if leaf not in picked:\n",
    "            picked.add(leaf)\n",
    "            if len(picked) == n:\n",
    "                break\n",
    "    return picked\n",
    "\n",
    "def tree_depth_leaf_two_stage_cv(\n",
    "    X,\n",
    "    y: Sequence[float],\n",
    "    *,\n",
    "    # Stage 1 (leaf tuning search space)\n",
    "    max_leaf_samples: int = 20,\n",
    "    leaf_values: Optional[Sequence[int]] = None,\n",
    "    # Stage 2 (depth grid)\n",
    "    max_depth: int = 20,\n",
    "    depths: Optional[Sequence[int]] = None,\n",
    "    # CV and selection\n",
    "    cv_folds: int = 3,\n",
    "    n: int = 5,                 # top-n per metric (no ties beyond n)\n",
    "    random_state: int = 702,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Two-stage CV procedure:\n",
    "\n",
    "    1) Tune min_samples_leaf alone:\n",
    "       - Evaluate a CV sweep over candidate min_samples_leaf values.\n",
    "       - For each metric, select the top-n UNIQUE min_samples_leaf values\n",
    "         (no ties beyond n):\n",
    "           * mean_RSS   (lower is better)\n",
    "           * mean_R2    (higher is better)\n",
    "           * RSS_range  (lower is better)\n",
    "           * R2_range   (lower is better)\n",
    "\n",
    "    2) Build a hyperparameter grid:\n",
    "       - Depth grid = all given depths (1..max_depth if not provided)\n",
    "       - Leaf grid  = UNION of the four top-n sets from step (1)\n",
    "         (unique deduped, sorted ascending).\n",
    "\n",
    "    3) Evaluate all (depth, min_samples_leaf) combinations via CV and\n",
    "       return a DataFrame with:\n",
    "         * depth\n",
    "         * min_samples_leaf\n",
    "         * folds\n",
    "         * mean_RSS\n",
    "         * mean_R2\n",
    "         * RSS_range  (max_RSS - min_RSS across folds)\n",
    "         * R2_range   (max_R2  - min_R2  across folds)\n",
    "    \"\"\"\n",
    "    # --- Normalize inputs ---\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).ravel()\n",
    "\n",
    "    if leaf_values is None:\n",
    "        leaf_values = range(1, max_leaf_samples + 1)\n",
    "    if depths is None:\n",
    "        depths = range(1, max_depth + 1)\n",
    "\n",
    "    # =========================\n",
    "    # Stage 1: tune min_samples_leaf\n",
    "    # =========================\n",
    "    leaf_rows = []\n",
    "    for leaf in leaf_values:\n",
    "        metrics = _cv_metrics_for_leaf(X, y, leaf=leaf, cv_folds=cv_folds, random_state=random_state)\n",
    "        leaf_rows.append(metrics)\n",
    "    leaf_df = pd.DataFrame(leaf_rows)\n",
    "\n",
    "    # Select top-n unique leafs per metric\n",
    "    top_by_mean_rss = _select_top_n_unique(leaf_df, \"mean_RSS\",  n, direction=\"lower\")\n",
    "    top_by_mean_r2  = _select_top_n_unique(leaf_df, \"mean_R2\",   n, direction=\"higher\")\n",
    "    top_by_rss_rng  = _select_top_n_unique(leaf_df, \"RSS_range\", n, direction=\"lower\")\n",
    "    top_by_r2_rng   = _select_top_n_unique(leaf_df, \"R2_range\",  n, direction=\"lower\")\n",
    "\n",
    "    # Union of all selected leaf values\n",
    "    tuned_leaf_grid = sorted(set().union(top_by_mean_rss, top_by_mean_r2, top_by_rss_rng, top_by_r2_rng))\n",
    "\n",
    "    # =========================\n",
    "    # Stage 2: evaluate depth × tuned_leaf_grid\n",
    "    # =========================\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    rows = []\n",
    "\n",
    "    for d in depths:\n",
    "        for leaf in tuned_leaf_grid:\n",
    "            rss_scores, r2_scores = [], []\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                model = DecisionTreeRegressor(\n",
    "                    max_depth=d,\n",
    "                    min_samples_leaf=leaf,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "                y_val  = y[val_idx]\n",
    "                y_pred = model.predict(X[val_idx])\n",
    "\n",
    "                rss_scores.append(float(np.sum((y_val - y_pred) ** 2)))\n",
    "                r2_scores.append(float(r2_score(y_val, y_pred)))\n",
    "\n",
    "            rows.append({\n",
    "                \"depth\": int(d),\n",
    "                \"min_samples_leaf\": int(leaf),\n",
    "                \"folds\": cv_folds,\n",
    "                \"mean_RSS\": float(np.mean(rss_scores)),\n",
    "                \"mean_R2\":  float(np.mean(r2_scores)),\n",
    "                \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "                \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "            })\n",
    "\n",
    "    # =========================\n",
    "    # Stage 3: return results\n",
    "    # =========================\n",
    "    results = pd.DataFrame(rows).sort_values(\n",
    "        [\"depth\", \"min_samples_leaf\"], ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca5c11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# takes ~6 seconds to run\n",
    "results_df = tree_depth_leaf_two_stage_cv(\n",
    "    X = x_data,\n",
    "    y = y_data,\n",
    "    max_leaf_samples=20,                       # leaf search space for Stage 1\n",
    "    #leaf_values=None,                          # or pass an explicit list\n",
    "    max_depth=20,                              # depth grid upper bound\n",
    "    #depths=[2, 4, 6, 8, 10, 12],               # or pass explicit depths\n",
    "    cv_folds=3,\n",
    "    n=5,\n",
    "    random_state=702\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e6283",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(by = 'mean_RSS',\n",
    "                       ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea10a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Tuple, Union\n",
    "\n",
    "def tuning_results(\n",
    "    cv_results: Union[Mapping[str, Any], Any],\n",
    "    n: int = 1,\n",
    "    round_digits: int = 6,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts the top-n hyperparameter tuning results from sklearn model\n",
    "    selection tools (GridSearchCV or RandomizedSearchCV). Outputs an organized\n",
    "    DataFrame containing:\n",
    "        * Model Rank       (rank_test_score)\n",
    "        * Mean Test Score  (mean_test_score)\n",
    "        * StDev Test Score (std_test_score)\n",
    "        * Best Parameters  (best_params)\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    cv_results : dict or fitted search object\n",
    "        Either the dictionary from `.cv_results_` or a fitted GridSearchCV /\n",
    "        RandomizedSearchCV object (the function will read `.cv_results_` if\n",
    "        present).\n",
    "    n : int, default=1\n",
    "        The number of top ranks to include. All rows with rank_test_score <= n\n",
    "        are returned (i.e., ties are included).\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "    # allow passing the fitted search object directly\n",
    "    if hasattr(cv_results, \"cv_results_\"):\n",
    "        cv_results = cv_results.cv_results_\n",
    "\n",
    "    # validation - ensuring dict-like object\n",
    "    if not isinstance(cv_results, Mapping):\n",
    "        raise TypeError(\"cv_results must be a dict-like object or a fitted search with .cv_results_\")\n",
    "    \n",
    "    # validation - checking keys\n",
    "    required = {\"params\", \"rank_test_score\", \"mean_test_score\"}\n",
    "    missing = required.difference(cv_results.keys())\n",
    "    if missing:\n",
    "        raise KeyError(f\"cv_results is missing required keys: {sorted(missing)}\")\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        # instantiating results DataFrame\n",
    "        df = pd.DataFrame(data = cv_results)[['rank_test_score',\n",
    "                                              'mean_test_score',\n",
    "                                              'std_test_score' ,\n",
    "                                              'params']]\n",
    "\n",
    "    except:\n",
    "        # instantiating partial results DataFrame\n",
    "        df = pd.DataFrame(data = cv_results)[['rank_test_score',\n",
    "                                              'mean_test_score',\n",
    "                                              'params']]\n",
    "        \n",
    "        # avoiding issue with older/custom scorers\n",
    "        if \"std_test_score\" not in df.columns:\n",
    "            df[\"std_test_score\"] = pd.NA\n",
    "        \n",
    "        \n",
    "        \n",
    "    # renaming columns\n",
    "    df = df.rename(columns={\"rank_test_score\": \"Model Rank\",\n",
    "                            \"mean_test_score\": \"Mean Test Score\",\n",
    "                            \"std_test_score\" : \"SD Test Score\",\n",
    "                            \"params\": \"Parameters\"})\n",
    "    \n",
    "    \n",
    "    # clamping n and filtering by rank (include ties)\n",
    "    n = max(int(n), 1)\n",
    "    top = df.loc[df[\"Model Rank\"] <= n].copy()\n",
    "\n",
    "    # sorting (highest rank followed by lowest standard deviation\n",
    "    top = top.sort_values([\"Model Rank\", \"SD Test Score\"],\n",
    "                          ascending=[True, False]).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3236eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence, Optional, Iterable, Set, Mapping, Any, Union\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error\n",
    "\n",
    "# --- assumes your tuning_results(cv_results, n, round_digits) is already defined in scope ---\n",
    "\n",
    "def _top_leafs_via_mean(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    leaf_values: Sequence[int],\n",
    "    cv: KFold,\n",
    "    scorer_name: str,\n",
    "    scorer,\n",
    "    n: int,\n",
    "    random_state: int,\n",
    ") -> Set[int]:\n",
    "    \"\"\"\n",
    "    Run GridSearchCV over min_samples_leaf with a single scorer,\n",
    "    pass to tuning_results, and pull the top-n unique leaf values.\n",
    "    \"\"\"\n",
    "    grid = {\"min_samples_leaf\": list(leaf_values)}\n",
    "    est  = DecisionTreeRegressor(random_state=random_state)\n",
    "    gs   = GridSearchCV(est, grid, scoring=scorer, cv=cv, refit=True, n_jobs=None)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    # Use the user's helper to extract top ranks (ties included)\n",
    "    top_df = tuning_results(gs, n=n)\n",
    "\n",
    "    # Extract unique leaf values from the returned Parameters column\n",
    "    return {int(p[\"min_samples_leaf\"]) for p in top_df[\"Parameters\"]}\n",
    "\n",
    "\n",
    "def _top_leafs_via_range(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    leaf_values: Sequence[int],\n",
    "    cv: KFold,\n",
    "    scorer_name: str,\n",
    "    scorer,\n",
    "    n: int,\n",
    "    random_state: int,\n",
    "    *,\n",
    "    convert_to_rss: bool = False,\n",
    "    split_sizes: Optional[Sequence[int]] = None,\n",
    ") -> Set[int]:\n",
    "    \"\"\"\n",
    "    Run GridSearchCV to capture split-wise scores, compute per-param RANGE across folds,\n",
    "    and return the top-n unique leafs with the *lowest* range.\n",
    "\n",
    "    If convert_to_rss=True, we interpret the scorer as neg_mean_squared_error and\n",
    "    transform split scores from MSE to RSS by multiplying by the split test size.\n",
    "    \"\"\"\n",
    "    grid = {\"min_samples_leaf\": list(leaf_values)}\n",
    "    est  = DecisionTreeRegressor(random_state=random_state)\n",
    "    gs   = GridSearchCV(est, grid, scoring=scorer, cv=cv, refit=True, n_jobs=None)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    cvres = gs.cv_results_\n",
    "    # Collect split columns present in cv_results_ for this scorer\n",
    "    # Columns are like 'split0_test_score' regardless of scorer name when a single scorer is used\n",
    "    split_cols = [c for c in cvres.keys() if c.startswith(\"split\") and c.endswith(\"_test_score\")]\n",
    "    split_cols = sorted(split_cols, key=lambda c: int(c.split(\"split\")[1].split(\"_\")[0]))\n",
    "\n",
    "    # Build a DataFrame with params and all split scores\n",
    "    df = pd.DataFrame({\n",
    "        \"min_samples_leaf\": [p[\"min_samples_leaf\"] for p in cvres[\"params\"]],\n",
    "        **{c: cvres[c] for c in split_cols}\n",
    "    })\n",
    "\n",
    "    # Optionally convert from scores to RSS if the scorer is neg_mean_squared_error\n",
    "    if convert_to_rss:\n",
    "        if split_sizes is None or len(split_sizes) != len(split_cols):\n",
    "            raise ValueError(\"split_sizes must be provided and match the number of CV splits when convert_to_rss=True.\")\n",
    "        for i, c in enumerate(split_cols):\n",
    "            # score = NEGATIVE MSE  ->  MSE = -score  ->  RSS = MSE * n_split\n",
    "            df[c] = (-df[c]) * int(split_sizes[i])\n",
    "\n",
    "    # Compute the range across splits\n",
    "    split_vals = df[split_cols].to_numpy()\n",
    "    ranges = split_vals.max(axis=1) - split_vals.min(axis=1)\n",
    "    df[\"metric_range\"] = ranges\n",
    "\n",
    "    # Pick top-n *lowest* ranges (no ties beyond n), stable by leaf ascending\n",
    "    df = df.sort_values([\"metric_range\", \"min_samples_leaf\"], ascending=[True, True])\n",
    "    picked: Set[int] = set()\n",
    "    out: Set[int] = set()\n",
    "    for _, row in df.iterrows():\n",
    "        leaf = int(row[\"min_samples_leaf\"])\n",
    "        if leaf not in picked:\n",
    "            picked.add(leaf)\n",
    "            out.add(leaf)\n",
    "            if len(out) == n:\n",
    "                break\n",
    "    return out\n",
    "\n",
    "\n",
    "def tree_depth_leaf_two_stage_cv_tuned(\n",
    "    X,\n",
    "    y: Sequence[float],\n",
    "    *,\n",
    "    # Stage 1 search space for leafs\n",
    "    max_leaf_samples: int = 20,\n",
    "    leaf_values: Optional[Sequence[int]] = None,\n",
    "    # Stage 2 depth grid\n",
    "    max_depth: int = 20,\n",
    "    depths: Optional[Sequence[int]] = None,\n",
    "    # CV + selection config\n",
    "    cv_folds: int = 3,\n",
    "    n: int = 5,                     # top-n per metric (include ties via tuning_results; capped to n unique in union)\n",
    "    random_state: int = 702,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Two-stage CV that *utilizes tuning_results* for mean-metric selection:\n",
    "\n",
    "    Stage 1 — Tune min_samples_leaf alone:\n",
    "      • Run GridSearchCV twice over min_samples_leaf:\n",
    "          - Scorer 1: neg_mean_squared_error (proxy for RSS; lower MSE -> lower RSS)\n",
    "          - Scorer 2: r2\n",
    "        Feed each search to `tuning_results(...)` to get the top-n (with ties) rows,\n",
    "        and collect their UNIQUE min_samples_leaf values.\n",
    "      • Also compute per-param RANGE across folds for:\n",
    "          - RSS_range (derived from neg_mean_squared_error × fold sizes)\n",
    "          - R2_range  (range of per-fold r2 scores)\n",
    "        Select the top-n UNIQUE leafs with the smallest ranges (no ties beyond n).\n",
    "\n",
    "      Final leaf grid = UNION of the four sets above.\n",
    "\n",
    "    Stage 2 — Evaluate full grid:\n",
    "      • Depth grid: all given depths (1..max_depth if not provided)\n",
    "      • Leaf grid : tuned set from Stage 1\n",
    "      • For every (depth, leaf) pair, compute CV metrics and return a DataFrame with:\n",
    "          depth, min_samples_leaf, folds, mean_RSS, mean_R2, RSS_range, R2_range\n",
    "    \"\"\"\n",
    "    # Normalize inputs\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).ravel()\n",
    "\n",
    "    if leaf_values is None:\n",
    "        leaf_values = list(range(1, max_leaf_samples + 1))\n",
    "    else:\n",
    "        leaf_values = list(leaf_values)\n",
    "\n",
    "    if depths is None:\n",
    "        depths = list(range(1, max_depth + 1))\n",
    "    else:\n",
    "        depths = list(depths)\n",
    "\n",
    "    # Construct a deterministic CV splitter we can reuse everywhere\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    # Precompute test split sizes so we can turn MSE into RSS later\n",
    "    split_sizes = [len(test_idx) for _, test_idx in kf.split(X)]\n",
    "\n",
    "    # ---- Stage 1A: mean metrics via tuning_results (GridSearchCV) ----\n",
    "    # mean_RSS (lower is better)  -> use neg_mean_squared_error\n",
    "    neg_mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    top_by_mean_rss = _top_leafs_via_mean(\n",
    "        X, y, leaf_values, kf, \"neg_mean_squared_error\", neg_mse_scorer, n, random_state\n",
    "    )\n",
    "\n",
    "    # mean_R2  (higher is better) -> use r2\n",
    "    r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "    top_by_mean_r2 = _top_leafs_via_mean(\n",
    "        X, y, leaf_values, kf, \"r2\", r2_scorer, n, random_state\n",
    "    )\n",
    "\n",
    "    # ---- Stage 1B: range metrics from split-wise scores (GridSearchCV) ----\n",
    "    # RSS_range (lower is better) using neg MSE -> convert to RSS using split sizes\n",
    "    top_by_rss_range = _top_leafs_via_range(\n",
    "        X, y, leaf_values, kf, \"neg_mean_squared_error\", neg_mse_scorer, n, random_state,\n",
    "        convert_to_rss=True, split_sizes=split_sizes\n",
    "    )\n",
    "\n",
    "    # R2_range (lower is better) directly from split r2 scores\n",
    "    top_by_r2_range = _top_leafs_via_range(\n",
    "        X, y, leaf_values, kf, \"r2\", r2_scorer, n, random_state,\n",
    "        convert_to_rss=False, split_sizes=None\n",
    "    )\n",
    "\n",
    "    # Union of leafs from the four criteria\n",
    "    tuned_leaf_grid = sorted(set().union(\n",
    "        top_by_mean_rss, top_by_mean_r2, top_by_rss_range, top_by_r2_range\n",
    "    ))\n",
    "\n",
    "    # ---- Stage 2: evaluate depth × tuned_leaf_grid and compute full metrics ----\n",
    "    rows = []\n",
    "    for d in depths:\n",
    "        for leaf in tuned_leaf_grid:\n",
    "            rss_scores, r2_scores = [], []\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                model = DecisionTreeRegressor(\n",
    "                    max_depth=d,\n",
    "                    min_samples_leaf=leaf,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "                y_val  = y[val_idx]\n",
    "                y_pred = model.predict(X[val_idx])\n",
    "\n",
    "                # Per-fold metrics\n",
    "                rss_scores.append(float(np.sum((y_val - y_pred) ** 2)))\n",
    "                r2_scores.append(float(r2_score(y_val, y_pred)))\n",
    "\n",
    "            rows.append({\n",
    "                \"depth\": int(d),\n",
    "                \"min_samples_leaf\": int(leaf),\n",
    "                \"folds\": cv_folds,\n",
    "                \"mean_RSS\": float(np.mean(rss_scores)),\n",
    "                \"mean_R2\":  float(np.mean(r2_scores)),\n",
    "                \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "                \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "            })\n",
    "\n",
    "    results = pd.DataFrame(rows).sort_values(\n",
    "        [\"depth\", \"min_samples_leaf\"], ascending=[True, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8551d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ~21 seconds\n",
    "results_df = tree_depth_leaf_two_stage_cv_tuned(\n",
    "    X = x_data,\n",
    "    y = y_data,\n",
    "    max_leaf_samples=200,                 # Stage-1 leaf search space\n",
    "    #leaf_values=None,                    # or an explicit list like [1,2,3,4,5,8,13,21]\n",
    "    max_depth=20,                        # Stage-2 depth search space\n",
    "    #depths=[2,4,6,8,10,12],              # or leave None to use 1..max_depth\n",
    "    cv_folds=3,\n",
    "    n=5,\n",
    "    random_state=702\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783ea64",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(by = 'mean_RSS',\n",
    "                       ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28230a6",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# set grid\n",
    "depths_list = [2, 4, 6, 8]\n",
    "leaf_list   = [1, 2, 5, 10]\n",
    "results_grid = tree_depth_leaf_cv_sweep(\n",
    "    X, y,\n",
    "    depths=depths_list,\n",
    "    leaf_values=leaf_list,\n",
    "    cv_folds=3,\n",
    "    random_state=702\n",
    ")\n",
    "print(results_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e691ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing each set\n",
    "#print(results_leaf.sort_values(by = 'mean_R2', ascending = False))\n",
    "#print(results.sort_values(by = 'mean_R2', ascending = False))\n",
    "print(all_results.sort_values(by = 'mean_R2', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc1bd9",
   "metadata": {},
   "source": [
    "### Checking combinations of the above v. brute force tuning.\n",
    "Step after this one: Do this as a range for whatever hps are in the top results.\n",
    "\n",
    "Each test resulted in the same indexes for RSS and R2, although in a multidimensional grid, the indexes did not follow the same order for these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## standard tuning grid ##\n",
    "depth_range = [1, 3, 4, 5, 6, 7, 8]\n",
    "leaf_range  = [8, 12, 13, 14, 15, 16, 17, 19, 20, 29, 30, 33]\n",
    "\n",
    "param_gr = {'max_depth'        : depth_range,\n",
    "            'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "model_type = DecisionTreeRegressor(random_state = 702)\n",
    "\n",
    "# placeholder df to store results\n",
    "combo_results = pd.DataFrame(data = None)\n",
    "\n",
    "# developing parameter grid\n",
    "param_grid = ParameterGrid(param_gr)\n",
    "\n",
    "## hp tuning ##\n",
    "for p in param_grid:\n",
    "    \n",
    "    # testing hyperparameter combinations\n",
    "    model = DecisionTreeRegressor(**p               ,\n",
    "                                  random_state = 702)\n",
    "\n",
    "    # storing results\n",
    "    results_2 = sklearn_tree_summary(x          = x_data,\n",
    "                                     y          = y_data,\n",
    "                                     model      = model,\n",
    "                                     model_name = f\"{dataset.split(sep = '.')[0]}_x-full_y-base\",\n",
    "                                     results_df = results_2,\n",
    "                                     f_names    = full_feature_names)\n",
    "\n",
    "# checking results\n",
    "results_2.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b053191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c577162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8304fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc2478",
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Tuple, Union, Iterable, Set\n",
    "import numpy  as np                            # numerical essentials\n",
    "import pandas as pd                            # data science essentials\n",
    "import statsmodels.api as sm                   # p-values\n",
    "from sklearn.model_selection import KFold      # cross validation\n",
    "from sklearn.metrics import r2_score           # r-squared\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "\n",
    "def _cv_metrics_for_leaf(\n",
    "    x_data: np.ndarray,\n",
    "    y_data: np.ndarray,\n",
    "    model_type: Optional[Callable[..., object]] = None,\n",
    "    leaf: int = 200,\n",
    "    cv_folds: int = 3,\n",
    "    random_state: int = 702,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Helper: compute CV metrics for a given min_samples_leaf value (Stage 1).\n",
    "    Uses a lightweight DecisionTreeRegressor model.\n",
    "\n",
    "    RETURNS a dict with: mean_RSS, mean_R2, RSS_range, R2_range\n",
    "    \"\"\"\n",
    "\n",
    "    # Default model type == DecisionTreeRegressor\n",
    "    if model_type is None:\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        model_type = DecisionTreeRegressor\n",
    "\n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data).ravel()\n",
    "\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    rss_scores = []\n",
    "    r2_scores  = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(x_data):\n",
    "        model = model_type(min_samples_leaf = leaf,\n",
    "                           random_state     = random_state)\n",
    "        \n",
    "        model.fit(x_data[train_idx], y_data[train_idx])\n",
    "\n",
    "        y_val  = y_data[val_idx]\n",
    "        y_pred = model.predict(x_data[val_idx])\n",
    "\n",
    "        rss_scores.append(float(np.sum((y_val - y_pred) ** 2)))\n",
    "        r2_scores.append(float(r2_score(y_val, y_pred)))\n",
    "\n",
    "    return {\n",
    "        \"min_samples_leaf\": int(leaf),\n",
    "        \"mean_RSS\":  float(np.mean(rss_scores)),\n",
    "        \"mean_R2\":   float(np.mean(r2_scores)),\n",
    "        \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "        \"R2_range\":  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "    }\n",
    "\n",
    "\n",
    "def _select_top_n_unique(\n",
    "    df: pd.DataFrame,\n",
    "    metric: str,\n",
    "    n: int,\n",
    "    asc: bool = True\n",
    ") -> Iterable[int]:\n",
    "    \"\"\"\n",
    "    Helper: select the top-n unique min_samples_leaf values by a metric.\n",
    "    direction: 'lower' or 'higher'. Does NOT include ties beyond n.\n",
    "    Stable secondary sort by min_samples_leaf ascending for determinism.\n",
    "    \"\"\"\n",
    "    \n",
    "    # sorting results\n",
    "    ranked = df.sort_values([metric, \"min_samples_leaf\"],\n",
    "                             ascending = asc,\n",
    "                             kind      = \"mergesort\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Keep first occurrence per leaf in the ranked order, then take the top n\n",
    "#     top = (\n",
    "#         ranked\n",
    "#         .drop_duplicates(subset=[\"min_samples_leaf\"], keep=\"first\")\n",
    "#         .head(n)[\"min_samples_leaf\"]\n",
    "#         .astype(int)\n",
    "#         .tolist()\n",
    "#     )\n",
    "    \n",
    "    return ranked.head(n=n)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# quick_tree (two-stage CV with lightweight estimator)\n",
    "# ===============================================================\n",
    "def quick_tree(\n",
    "    x_data,\n",
    "    y_data: Sequence[float],\n",
    "    model_type: Callable[..., object] = None,\n",
    "    max_leaf_samples: int = 50,\n",
    "    leaf_values: Optional[Sequence[int]] = None,\n",
    "    max_depth: int = 20,\n",
    "    depths: Optional[Sequence[int]] = None,\n",
    "    cv_folds: int = 3,\n",
    "    n: int = 5,\n",
    "    random_state: int = 702,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Quickly tunes a tree-based model using a two-stage cross-validated\n",
    "    procedure.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    x_data            | array-like | feature matrix                               | No default\n",
    "    y_data            | array-like | target vector                                | No default\n",
    "    model_type        | model      | tree-based model type                        | Default = DTree (Reg)\n",
    "    max_leaf_samples  | int        | largest min_samples_leaf if leaf_values None | Default = 50\n",
    "    leaf_values       | seq[int]   | explicit set of min_samples_leaf candidates  | Default = None\n",
    "    max_depth         | int        | largest depth tested if depths None          | Default = 20\n",
    "    depths            | seq[int]   | explicit set of depths to evaluate           | Default = None\n",
    "    cv_folds          | int        | number of CV folds                           | Default = 3\n",
    "    n                 | int        | top-n unique per metric (no ties beyond n)   | Default = 5\n",
    "    random_state      | int        | RNG seed for KFold and models                | Default = 702\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    DataFrame with:\n",
    "      * depth\n",
    "      * min_samples_leaf\n",
    "      * folds\n",
    "      * mean_RSS\n",
    "      * mean_R2\n",
    "      * RSS_range (max_RSS - min_RSS across folds)\n",
    "      * R2_range  (max_R2  - min_R2  across folds)\n",
    "    \"\"\"\n",
    "\n",
    "    # Default model type == DecisionTreeRegressor\n",
    "    if model_type is None:\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        model_type = DecisionTreeRegressor\n",
    "\n",
    "    # --- Normalize inputs ---\n",
    "    X = np.asarray(x_data)\n",
    "    y = np.asarray(y_data).ravel()\n",
    "\n",
    "    if leaf_values is None:\n",
    "        leaf_values = range(1, max_leaf_samples + 1)\n",
    "    if depths is None:\n",
    "        depths = range(1, max_depth + 1)\n",
    "\n",
    "    # =========================\n",
    "    # Stage 1: tune min_samples_leaf (ALWAYS lightweight estimator)\n",
    "    # =========================\n",
    "    leaf_rows = []\n",
    "    for leaf in leaf_values:\n",
    "        metrics = _cv_metrics_for_leaf(\n",
    "            X, y,\n",
    "            model_type=model_type,\n",
    "            leaf=leaf,\n",
    "            cv_folds=cv_folds,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        leaf_rows.append(metrics)\n",
    "    leaf_df = pd.DataFrame(leaf_rows)\n",
    "\n",
    "    # Select top-n unique leafs per metric\n",
    "    top_by_mean_rss = _select_top_n_unique(leaf_df, \"mean_RSS\",  n, asc=True)\n",
    "    top_by_mean_r2  = _select_top_n_unique(leaf_df, \"mean_R2\",   n, asc=False)\n",
    "    top_by_rss_rng  = _select_top_n_unique(leaf_df, \"RSS_range\", n, asc=True)\n",
    "    top_by_r2_rng   = _select_top_n_unique(leaf_df, \"R2_range\",  n, asc=True)\n",
    "\n",
    "    \n",
    "    # concatenating results and dropping duplicates\n",
    "    tuned_leaves = pd.concat(objs = [top_by_mean_rss,\n",
    "                                     top_by_mean_r2,\n",
    "                                     top_by_rss_rng,\n",
    "                                     top_by_r2_rng],\n",
    "                             axis = 0).drop_duplicates()\n",
    "    \n",
    "    \n",
    "    # preparing leaf values\n",
    "    tuned_leaf_grid = tuned_leaves['min_samples_leaf']\n",
    "\n",
    "\n",
    "    # =========================\n",
    "    # Stage 2: evaluate depth × tuned_leaf_grid with final model_type\n",
    "    # =========================\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    rows = []\n",
    "\n",
    "    for d in depths:\n",
    "        for leaf in tuned_leaf_grid:\n",
    "            rss_scores, r2_scores = [], []\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                model = model_type(\n",
    "                    max_depth=d,\n",
    "                    min_samples_leaf=leaf,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "                y_val  = y[val_idx]\n",
    "                y_pred = model.predict(X[val_idx])\n",
    "\n",
    "                rss_scores.append(float(np.sum((y_val - y_pred) ** 2)))\n",
    "                r2_scores.append(float(r2_score(y_val, y_pred)))\n",
    "\n",
    "            rows.append({\n",
    "                \"depth\": int(d),\n",
    "                \"min_samples_leaf\": int(leaf),\n",
    "                \"folds\": cv_folds,\n",
    "                \"mean_RSS\" : float(np.mean(rss_scores)),\n",
    "                \"mean_R2\"  :  float(np.mean(r2_scores)),\n",
    "                \"RSS_range\": float(np.max(rss_scores) - np.min(rss_scores)),\n",
    "                \"R2_range\" :  float(np.max(r2_scores)  - np.min(r2_scores)),\n",
    "            })\n",
    "\n",
    "    \n",
    "    # preparing DataFrame\n",
    "    depth_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # selecting the top models per metric\n",
    "    top_by_mean_rss = _select_top_n_unique(depth_df, \"mean_RSS\",  n, asc=True)\n",
    "    top_by_mean_r2  = _select_top_n_unique(depth_df, \"mean_R2\",   n, asc=False)\n",
    "    top_by_rss_rng  = _select_top_n_unique(depth_df, \"RSS_range\", n, asc=True)\n",
    "    top_by_r2_rng   = _select_top_n_unique(depth_df, \"R2_range\",  n, asc=True)\n",
    "    \n",
    "    # concatenating results and dropping duplicates\n",
    "    tuned_depth = pd.concat(objs = [top_by_mean_rss,\n",
    "                                    top_by_mean_r2 ,\n",
    "                                    top_by_rss_rng ,\n",
    "                                    top_by_r2_rng] ,\n",
    "                            axis = 0).drop_duplicates()\\\n",
    "                                     .sort_values(by='mean_RSS')\\\n",
    "                                     .reset_index()\n",
    "    \n",
    "    return tuned_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c5104",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# line 175\n",
    "\n",
    "quick_tree(x_data           = x_data,\n",
    "           y_data           = y_data,\n",
    "           max_leaf_samples = 50,\n",
    "           max_depth        = 10,\n",
    "           n                = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "## quick neighbors ##\n",
    "def quick_neighbors(x_data,\n",
    "                    y_data,\n",
    "                    standardize = True, # use simple_scaler\n",
    "                    metric      = 'minkowski',\n",
    "                    algorithm   = 'auto',\n",
    "                    weights     = 'uniform'\n",
    "                    njobs       = -1):\n",
    "    \"\"\"\n",
    "    Stages:\n",
    "    1. Standardizes the data.\n",
    "    2. Find the top n number of neighbors on training and testing sets.\n",
    "    3. Test the top neighbors on p... see if this changes the top neighbors.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(KNeighborsRegressor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
